{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Base code\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device:  cuda\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "import logging\n",
    "import utils.gpu as gpu\n",
    "from model.yolov3 import Yolov3\n",
    "from model.loss.yolo_loss import YoloV3Loss\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "from torch.utils.data import DataLoader\n",
    "import utils.datasets as data\n",
    "import time\n",
    "import random\n",
    "import argparse\n",
    "from eval.evaluator import *\n",
    "from utils.tools import *\n",
    "from tensorboardX import SummaryWriter\n",
    "import config.yolov3_config_voc as cfg\n",
    "from utils import cosine_lr_scheduler\n",
    "\n",
    "\n",
    "# GPU device\n",
    "# Check GPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"Device: \", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer(object):\n",
    "    def __init__(self,  weight_path='./weight/darknet53_448.weights', resume=None, gpu_id='0'):\n",
    "        init_seeds(0)\n",
    "        self.device = gpu.select_device(gpu_id)\n",
    "        self.start_epoch = 0\n",
    "        self.best_mAP = 0.\n",
    "        self.epochs = cfg.TRAIN[\"EPOCHS\"]\n",
    "        self.weight_path = weight_path\n",
    "        self.multi_scale_train = cfg.TRAIN[\"MULTI_SCALE_TRAIN\"]\n",
    "        self.train_dataset = data.VocDataset(anno_file_type=\"train\", img_size=cfg.TRAIN[\"TRAIN_IMG_SIZE\"])\n",
    "        self.train_dataloader = DataLoader(self.train_dataset,\n",
    "                                           batch_size=cfg.TRAIN[\"BATCH_SIZE\"],\n",
    "                                           num_workers=cfg.TRAIN[\"NUMBER_WORKERS\"],\n",
    "                                           shuffle=True)\n",
    "        self.yolov3 = Yolov3().to(self.device)\n",
    "        # self.yolov3.apply(tools.weights_init_normal)\n",
    "\n",
    "        self.optimizer = optim.SGD(self.yolov3.parameters(), lr=cfg.TRAIN[\"LR_INIT\"],\n",
    "                                   momentum=cfg.TRAIN[\"MOMENTUM\"], weight_decay=cfg.TRAIN[\"WEIGHT_DECAY\"])\n",
    "        #self.optimizer = optim.Adam(self.yolov3.parameters(), lr = lr_init, weight_decay=0.9995)\n",
    "\n",
    "        self.criterion = YoloV3Loss(anchors=cfg.MODEL[\"ANCHORS\"], strides=cfg.MODEL[\"STRIDES\"],\n",
    "                                    iou_threshold_loss=cfg.TRAIN[\"IOU_THRESHOLD_LOSS\"])\n",
    "\n",
    "#         self.__load_model_weights(weight_path, resume)\n",
    "\n",
    "        self.scheduler = cosine_lr_scheduler.CosineDecayLR(self.optimizer,\n",
    "                                                          T_max=self.epochs*len(self.train_dataloader),\n",
    "                                                          lr_init=cfg.TRAIN[\"LR_INIT\"],\n",
    "                                                          lr_min=cfg.TRAIN[\"LR_END\"],\n",
    "                                                          warmup=cfg.TRAIN[\"WARMUP_EPOCHS\"]*len(self.train_dataloader))\n",
    "\n",
    "\n",
    "#     def __load_model_weights(self, weight_path, resume):\n",
    "#         if resume:\n",
    "#             last_weight = os.path.join(os.path.split(weight_path)[0], \"last.pt\")\n",
    "#             chkpt = torch.load(last_weight, map_location=self.device)\n",
    "#             self.yolov3.load_state_dict(chkpt['model'])\n",
    "\n",
    "#             self.start_epoch = chkpt['epoch'] + 1\n",
    "#             if chkpt['optimizer'] is not None:\n",
    "#                 self.optimizer.load_state_dict(chkpt['optimizer'])\n",
    "#                 self.best_mAP = chkpt['best_mAP']\n",
    "#             del chkpt\n",
    "#         else:\n",
    "#             self.yolov3.load_darknet_weights(weight_path)\n",
    "\n",
    "\n",
    "#     def __save_model_weights(self, epoch, mAP):\n",
    "#         if mAP > self.best_mAP:\n",
    "#             self.best_mAP = mAP\n",
    "#         best_weight = os.path.join(os.path.split(self.weight_path)[0], \"best.pt\")\n",
    "#         last_weight = os.path.join(os.path.split(self.weight_path)[0], \"last.pt\")\n",
    "#         chkpt = {'epoch': epoch,\n",
    "#                  'best_mAP': self.best_mAP,\n",
    "#                  'model': self.yolov3.state_dict(),\n",
    "#                  'optimizer': self.optimizer.state_dict()}\n",
    "#         print(\"save model: \", last_weight)\n",
    "#         torch.save(chkpt, last_weight)\n",
    "\n",
    "#         if self.best_mAP == mAP:\n",
    "#             torch.save(chkpt['model'], best_weight)\n",
    "\n",
    "#         if epoch > 0 and epoch % 10 == 0:\n",
    "#             torch.save(chkpt, os.path.join(os.path.split(self.weight_path)[0], 'backup_epoch%g.pt'%epoch))\n",
    "#         del chkpt\n",
    "\n",
    "\n",
    "    def train(self):\n",
    "        print(self.yolov3)\n",
    "        print(\"Train datasets number is : {}\".format(len(self.train_dataset)))\n",
    "\n",
    "        for epoch in range(self.start_epoch, self.epochs):\n",
    "            self.yolov3.train()\n",
    "\n",
    "            mloss = torch.zeros(4)\n",
    "            for i, (imgs, label_sbbox, label_mbbox, label_lbbox, sbboxes, mbboxes, lbboxes)  in enumerate(self.train_dataloader):\n",
    "\n",
    "                self.scheduler.step(len(self.train_dataloader)*epoch + i)\n",
    "\n",
    "                imgs = imgs.to(self.device)\n",
    "                label_sbbox = label_sbbox.to(self.device)\n",
    "                label_mbbox = label_mbbox.to(self.device)\n",
    "                label_lbbox = label_lbbox.to(self.device)\n",
    "                sbboxes = sbboxes.to(self.device)\n",
    "                mbboxes = mbboxes.to(self.device)\n",
    "                lbboxes = lbboxes.to(self.device)\n",
    "\n",
    "                p, p_d = self.yolov3(imgs)\n",
    "\n",
    "                loss, loss_giou, loss_conf, loss_cls = self.criterion(p, p_d, label_sbbox, label_mbbox,\n",
    "                                                  label_lbbox, sbboxes, mbboxes, lbboxes)\n",
    "\n",
    "                self.optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "\n",
    "                # Update running mean of tracked metrics\n",
    "                loss_items = torch.tensor([loss_giou, loss_conf, loss_cls, loss])\n",
    "                mloss = (mloss * i + loss_items) / (i + 1)\n",
    "\n",
    "                # Print batch results\n",
    "                if i%10==0:\n",
    "                    s = ('Epoch:[ %d | %d ]    Batch:[ %d | %d ]    loss_giou: %.4f    loss_conf: %.4f    loss_cls: %.4f    loss: %.4f    '\n",
    "                         'lr: %g') % (epoch, self.epochs - 1, i, len(self.train_dataloader) - 1, mloss[0],mloss[1], mloss[2], mloss[3],\n",
    "                                      self.optimizer.param_groups[0]['lr'])\n",
    "                    print(s)\n",
    "\n",
    "                # multi-sclae training (320-608 pixels) every 10 batches\n",
    "#                 if self.multi_scale_train and (i+1)%10 == 0:\n",
    "#                     self.train_dataset.img_size = random.choice(range(10,20)) * 32\n",
    "#                     print(\"multi_scale_img_size : {}\".format(self.train_dataset.img_size))\n",
    "                \n",
    "                \n",
    "            #\n",
    "            best_weight = os.path.join(os.path.split(self.weight_path)[0], \"best.pt\")\n",
    "            chkpt = {'epoch': epoch,\n",
    "                    'model': self.yolov3.state_dict(),\n",
    "                    'optimizer': self.optimizer.state_dict()}\n",
    "            print(\"save model: \", best_weight)\n",
    "            torch.save(chkpt, best_weight)\n",
    "\n",
    "#             mAP = 0\n",
    "#             if epoch >= 20:\n",
    "# #                 print('*'*20+\"Validate\"+'*'*20)\n",
    "#                 with torch.no_grad():\n",
    "#                     APs = Evaluator(self.yolov3).APs_voc()\n",
    "#                     for i in APs:\n",
    "# #                         print(\"{} --> mAP : {}\".format(i, APs[i]))\n",
    "#                         mAP += APs[i]\n",
    "#                     mAP = mAP / self.train_dataset.num_classes\n",
    "# #                     print('mAP:%g'%(mAP))\n",
    "\n",
    "#             self.__save_model_weights(epoch, mAP)\n",
    "#             print('best mAP : %g' % (self.best_mAP))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CUDA device0 _CudaDeviceProperties(name='TITAN RTX', total_memory=24220MB)\n",
      "initing Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "initing BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "initing Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "initing BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "initing Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "initing BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "initing Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "initing BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "initing Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "initing BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "initing Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "initing BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "initing Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "initing BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "initing Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "initing BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "initing Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "initing BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "initing Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "initing BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "initing Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "initing BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "initing Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "initing BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "initing Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "initing BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "initing Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "initing BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "initing Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "initing BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "initing Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "initing BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "initing Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "initing BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "initing Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "initing BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "initing Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "initing BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "initing Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "initing BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "initing Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "initing BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "initing Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "initing BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "initing Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "initing BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "initing Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "initing BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "initing Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "initing BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "initing Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "initing BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "initing Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "initing BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "initing Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "initing BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "initing Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "initing BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "initing Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "initing BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "initing Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "initing BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "initing Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "initing BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "initing Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "initing BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "initing Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "initing BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "initing Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "initing BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "initing Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "initing BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "initing Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "initing BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "initing Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "initing BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "initing Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "initing BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "initing Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "initing BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "initing Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "initing BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "initing Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "initing BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "initing Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "initing BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "initing Conv2d(512, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "initing BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "initing Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "initing BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "initing Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "initing BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "initing Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "initing BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "initing Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "initing BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "initing Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "initing BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "initing Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "initing BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "initing Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "initing BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "initing Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "initing BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "initing Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "initing BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "initing Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "initing BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "initing Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "initing BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "initing Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "initing BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "initing Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "initing BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "initing Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "initing BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "initing Conv2d(1024, 33, kernel_size=(1, 1), stride=(1, 1))\n",
      "initing Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "initing BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "initing Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "initing BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "initing Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "initing BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "initing Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "initing BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "initing Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "initing BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "initing Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "initing BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "initing Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "initing BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "initing Conv2d(512, 33, kernel_size=(1, 1), stride=(1, 1))\n",
      "initing Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "initing BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "initing Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "initing BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "initing Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "initing BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "initing Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "initing BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "initing Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "initing BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "initing Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "initing BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "initing Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "initing BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "initing Conv2d(256, 33, kernel_size=(1, 1), stride=(1, 1))\n",
      "Yolov3(\n",
      "  (_Yolov3__backnone): Darknet53(\n",
      "    (_Darknet53__conv): Convolutional(\n",
      "      (_Convolutional__conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (_Convolutional__norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (_Convolutional__activate): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (_Darknet53__conv_5_0): Convolutional(\n",
      "      (_Convolutional__conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (_Convolutional__norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (_Convolutional__activate): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (_Darknet53__rb_5_0): Residual_block(\n",
      "      (_Residual_block__conv1): Convolutional(\n",
      "        (_Convolutional__conv): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (_Convolutional__norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (_Convolutional__activate): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      )\n",
      "      (_Residual_block__conv2): Convolutional(\n",
      "        (_Convolutional__conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (_Convolutional__norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (_Convolutional__activate): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (_Darknet53__conv_5_1): Convolutional(\n",
      "      (_Convolutional__conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (_Convolutional__norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (_Convolutional__activate): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (_Darknet53__rb_5_1_0): Residual_block(\n",
      "      (_Residual_block__conv1): Convolutional(\n",
      "        (_Convolutional__conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (_Convolutional__norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (_Convolutional__activate): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      )\n",
      "      (_Residual_block__conv2): Convolutional(\n",
      "        (_Convolutional__conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (_Convolutional__norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (_Convolutional__activate): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (_Darknet53__rb_5_1_1): Residual_block(\n",
      "      (_Residual_block__conv1): Convolutional(\n",
      "        (_Convolutional__conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (_Convolutional__norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (_Convolutional__activate): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      )\n",
      "      (_Residual_block__conv2): Convolutional(\n",
      "        (_Convolutional__conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (_Convolutional__norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (_Convolutional__activate): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (_Darknet53__conv_5_2): Convolutional(\n",
      "      (_Convolutional__conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (_Convolutional__norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (_Convolutional__activate): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (_Darknet53__rb_5_2_0): Residual_block(\n",
      "      (_Residual_block__conv1): Convolutional(\n",
      "        (_Convolutional__conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (_Convolutional__norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (_Convolutional__activate): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      )\n",
      "      (_Residual_block__conv2): Convolutional(\n",
      "        (_Convolutional__conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (_Convolutional__norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (_Convolutional__activate): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (_Darknet53__rb_5_2_1): Residual_block(\n",
      "      (_Residual_block__conv1): Convolutional(\n",
      "        (_Convolutional__conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (_Convolutional__norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (_Convolutional__activate): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      )\n",
      "      (_Residual_block__conv2): Convolutional(\n",
      "        (_Convolutional__conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (_Convolutional__norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (_Convolutional__activate): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (_Darknet53__rb_5_2_2): Residual_block(\n",
      "      (_Residual_block__conv1): Convolutional(\n",
      "        (_Convolutional__conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (_Convolutional__norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (_Convolutional__activate): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      )\n",
      "      (_Residual_block__conv2): Convolutional(\n",
      "        (_Convolutional__conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (_Convolutional__norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (_Convolutional__activate): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (_Darknet53__rb_5_2_3): Residual_block(\n",
      "      (_Residual_block__conv1): Convolutional(\n",
      "        (_Convolutional__conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (_Convolutional__norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (_Convolutional__activate): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      )\n",
      "      (_Residual_block__conv2): Convolutional(\n",
      "        (_Convolutional__conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (_Convolutional__norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (_Convolutional__activate): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (_Darknet53__rb_5_2_4): Residual_block(\n",
      "      (_Residual_block__conv1): Convolutional(\n",
      "        (_Convolutional__conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (_Convolutional__norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (_Convolutional__activate): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      )\n",
      "      (_Residual_block__conv2): Convolutional(\n",
      "        (_Convolutional__conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (_Convolutional__norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (_Convolutional__activate): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (_Darknet53__rb_5_2_5): Residual_block(\n",
      "      (_Residual_block__conv1): Convolutional(\n",
      "        (_Convolutional__conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (_Convolutional__norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (_Convolutional__activate): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      )\n",
      "      (_Residual_block__conv2): Convolutional(\n",
      "        (_Convolutional__conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (_Convolutional__norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (_Convolutional__activate): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (_Darknet53__rb_5_2_6): Residual_block(\n",
      "      (_Residual_block__conv1): Convolutional(\n",
      "        (_Convolutional__conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (_Convolutional__norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (_Convolutional__activate): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      )\n",
      "      (_Residual_block__conv2): Convolutional(\n",
      "        (_Convolutional__conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (_Convolutional__norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (_Convolutional__activate): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (_Darknet53__rb_5_2_7): Residual_block(\n",
      "      (_Residual_block__conv1): Convolutional(\n",
      "        (_Convolutional__conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (_Convolutional__norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (_Convolutional__activate): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      )\n",
      "      (_Residual_block__conv2): Convolutional(\n",
      "        (_Convolutional__conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (_Convolutional__norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (_Convolutional__activate): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (_Darknet53__conv_5_3): Convolutional(\n",
      "      (_Convolutional__conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (_Convolutional__norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (_Convolutional__activate): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (_Darknet53__rb_5_3_0): Residual_block(\n",
      "      (_Residual_block__conv1): Convolutional(\n",
      "        (_Convolutional__conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (_Convolutional__norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (_Convolutional__activate): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      )\n",
      "      (_Residual_block__conv2): Convolutional(\n",
      "        (_Convolutional__conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (_Convolutional__norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (_Convolutional__activate): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (_Darknet53__rb_5_3_1): Residual_block(\n",
      "      (_Residual_block__conv1): Convolutional(\n",
      "        (_Convolutional__conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (_Convolutional__norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (_Convolutional__activate): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      )\n",
      "      (_Residual_block__conv2): Convolutional(\n",
      "        (_Convolutional__conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (_Convolutional__norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (_Convolutional__activate): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (_Darknet53__rb_5_3_2): Residual_block(\n",
      "      (_Residual_block__conv1): Convolutional(\n",
      "        (_Convolutional__conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (_Convolutional__norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (_Convolutional__activate): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      )\n",
      "      (_Residual_block__conv2): Convolutional(\n",
      "        (_Convolutional__conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (_Convolutional__norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (_Convolutional__activate): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (_Darknet53__rb_5_3_3): Residual_block(\n",
      "      (_Residual_block__conv1): Convolutional(\n",
      "        (_Convolutional__conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (_Convolutional__norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (_Convolutional__activate): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      )\n",
      "      (_Residual_block__conv2): Convolutional(\n",
      "        (_Convolutional__conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (_Convolutional__norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (_Convolutional__activate): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (_Darknet53__rb_5_3_4): Residual_block(\n",
      "      (_Residual_block__conv1): Convolutional(\n",
      "        (_Convolutional__conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (_Convolutional__norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (_Convolutional__activate): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      )\n",
      "      (_Residual_block__conv2): Convolutional(\n",
      "        (_Convolutional__conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (_Convolutional__norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (_Convolutional__activate): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (_Darknet53__rb_5_3_5): Residual_block(\n",
      "      (_Residual_block__conv1): Convolutional(\n",
      "        (_Convolutional__conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (_Convolutional__norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (_Convolutional__activate): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      )\n",
      "      (_Residual_block__conv2): Convolutional(\n",
      "        (_Convolutional__conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (_Convolutional__norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (_Convolutional__activate): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (_Darknet53__rb_5_3_6): Residual_block(\n",
      "      (_Residual_block__conv1): Convolutional(\n",
      "        (_Convolutional__conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (_Convolutional__norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (_Convolutional__activate): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      )\n",
      "      (_Residual_block__conv2): Convolutional(\n",
      "        (_Convolutional__conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (_Convolutional__norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (_Convolutional__activate): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (_Darknet53__rb_5_3_7): Residual_block(\n",
      "      (_Residual_block__conv1): Convolutional(\n",
      "        (_Convolutional__conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (_Convolutional__norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (_Convolutional__activate): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      )\n",
      "      (_Residual_block__conv2): Convolutional(\n",
      "        (_Convolutional__conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (_Convolutional__norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (_Convolutional__activate): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (_Darknet53__conv_5_4): Convolutional(\n",
      "      (_Convolutional__conv): Conv2d(512, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (_Convolutional__norm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (_Convolutional__activate): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (_Darknet53__rb_5_4_0): Residual_block(\n",
      "      (_Residual_block__conv1): Convolutional(\n",
      "        (_Convolutional__conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (_Convolutional__norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (_Convolutional__activate): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      )\n",
      "      (_Residual_block__conv2): Convolutional(\n",
      "        (_Convolutional__conv): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (_Convolutional__norm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (_Convolutional__activate): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (_Darknet53__rb_5_4_1): Residual_block(\n",
      "      (_Residual_block__conv1): Convolutional(\n",
      "        (_Convolutional__conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (_Convolutional__norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (_Convolutional__activate): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      )\n",
      "      (_Residual_block__conv2): Convolutional(\n",
      "        (_Convolutional__conv): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (_Convolutional__norm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (_Convolutional__activate): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (_Darknet53__rb_5_4_2): Residual_block(\n",
      "      (_Residual_block__conv1): Convolutional(\n",
      "        (_Convolutional__conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (_Convolutional__norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (_Convolutional__activate): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      )\n",
      "      (_Residual_block__conv2): Convolutional(\n",
      "        (_Convolutional__conv): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (_Convolutional__norm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (_Convolutional__activate): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (_Darknet53__rb_5_4_3): Residual_block(\n",
      "      (_Residual_block__conv1): Convolutional(\n",
      "        (_Convolutional__conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (_Convolutional__norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (_Convolutional__activate): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      )\n",
      "      (_Residual_block__conv2): Convolutional(\n",
      "        (_Convolutional__conv): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (_Convolutional__norm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (_Convolutional__activate): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (_Yolov3__fpn): FPN_YOLOV3(\n",
      "    (_FPN_YOLOV3__conv_set_0): Sequential(\n",
      "      (0): Convolutional(\n",
      "        (_Convolutional__conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (_Convolutional__norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (_Convolutional__activate): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      )\n",
      "      (1): Convolutional(\n",
      "        (_Convolutional__conv): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (_Convolutional__norm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (_Convolutional__activate): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      )\n",
      "      (2): Convolutional(\n",
      "        (_Convolutional__conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (_Convolutional__norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (_Convolutional__activate): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      )\n",
      "      (3): Convolutional(\n",
      "        (_Convolutional__conv): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (_Convolutional__norm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (_Convolutional__activate): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      )\n",
      "      (4): Convolutional(\n",
      "        (_Convolutional__conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (_Convolutional__norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (_Convolutional__activate): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (_FPN_YOLOV3__conv0_0): Convolutional(\n",
      "      (_Convolutional__conv): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (_Convolutional__norm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (_Convolutional__activate): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (_FPN_YOLOV3__conv0_1): Convolutional(\n",
      "      (_Convolutional__conv): Conv2d(1024, 33, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (_FPN_YOLOV3__conv0): Convolutional(\n",
      "      (_Convolutional__conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (_Convolutional__norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (_Convolutional__activate): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (_FPN_YOLOV3__upsample0): Upsample()\n",
      "    (_FPN_YOLOV3__route0): Route()\n",
      "    (_FPN_YOLOV3__conv_set_1): Sequential(\n",
      "      (0): Convolutional(\n",
      "        (_Convolutional__conv): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (_Convolutional__norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (_Convolutional__activate): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      )\n",
      "      (1): Convolutional(\n",
      "        (_Convolutional__conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (_Convolutional__norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (_Convolutional__activate): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      )\n",
      "      (2): Convolutional(\n",
      "        (_Convolutional__conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (_Convolutional__norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (_Convolutional__activate): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      )\n",
      "      (3): Convolutional(\n",
      "        (_Convolutional__conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (_Convolutional__norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (_Convolutional__activate): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      )\n",
      "      (4): Convolutional(\n",
      "        (_Convolutional__conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (_Convolutional__norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (_Convolutional__activate): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (_FPN_YOLOV3__conv1_0): Convolutional(\n",
      "      (_Convolutional__conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (_Convolutional__norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (_Convolutional__activate): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (_FPN_YOLOV3__conv1_1): Convolutional(\n",
      "      (_Convolutional__conv): Conv2d(512, 33, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (_FPN_YOLOV3__conv1): Convolutional(\n",
      "      (_Convolutional__conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (_Convolutional__norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (_Convolutional__activate): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (_FPN_YOLOV3__upsample1): Upsample()\n",
      "    (_FPN_YOLOV3__route1): Route()\n",
      "    (_FPN_YOLOV3__conv_set_2): Sequential(\n",
      "      (0): Convolutional(\n",
      "        (_Convolutional__conv): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (_Convolutional__norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (_Convolutional__activate): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      )\n",
      "      (1): Convolutional(\n",
      "        (_Convolutional__conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (_Convolutional__norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (_Convolutional__activate): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      )\n",
      "      (2): Convolutional(\n",
      "        (_Convolutional__conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (_Convolutional__norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (_Convolutional__activate): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      )\n",
      "      (3): Convolutional(\n",
      "        (_Convolutional__conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (_Convolutional__norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (_Convolutional__activate): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      )\n",
      "      (4): Convolutional(\n",
      "        (_Convolutional__conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (_Convolutional__norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (_Convolutional__activate): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (_FPN_YOLOV3__conv2_0): Convolutional(\n",
      "      (_Convolutional__conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (_Convolutional__norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (_Convolutional__activate): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (_FPN_YOLOV3__conv2_1): Convolutional(\n",
      "      (_Convolutional__conv): Conv2d(256, 33, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      "  (_Yolov3__head_s): Yolo_head()\n",
      "  (_Yolov3__head_m): Yolo_head()\n",
      "  (_Yolov3__head_l): Yolo_head()\n",
      ")\n",
      "Train datasets number is : 2089\n",
      "Epoch:[ 0 | 29 ]    Batch:[ 0 | 130 ]    loss_giou: 21.6768    loss_conf: 1766.0385    loss_cls: 83.9549    loss: 1871.6702    lr: 0\n",
      "Epoch:[ 0 | 29 ]    Batch:[ 10 | 130 ]    loss_giou: 21.4164    loss_conf: 931.6868    loss_cls: 85.4534    loss: 1038.5565    lr: 7.63359e-06\n",
      "Epoch:[ 0 | 29 ]    Batch:[ 20 | 130 ]    loss_giou: 20.1460    loss_conf: 509.5299    loss_cls: 83.0698    loss: 612.7458    lr: 1.52672e-05\n",
      "Epoch:[ 0 | 29 ]    Batch:[ 30 | 130 ]    loss_giou: 18.8266    loss_conf: 354.1995    loss_cls: 80.7041    loss: 453.7301    lr: 2.29008e-05\n",
      "Epoch:[ 0 | 29 ]    Batch:[ 40 | 130 ]    loss_giou: 17.3449    loss_conf: 273.0425    loss_cls: 77.1375    loss: 367.5247    lr: 3.05344e-05\n",
      "Epoch:[ 0 | 29 ]    Batch:[ 50 | 130 ]    loss_giou: 16.3765    loss_conf: 222.7725    loss_cls: 73.3250    loss: 312.4739    lr: 3.81679e-05\n",
      "Epoch:[ 0 | 29 ]    Batch:[ 60 | 130 ]    loss_giou: 15.6900    loss_conf: 188.5807    loss_cls: 69.2390    loss: 273.5095    lr: 4.58015e-05\n",
      "Epoch:[ 0 | 29 ]    Batch:[ 70 | 130 ]    loss_giou: 15.1058    loss_conf: 163.4606    loss_cls: 65.1655    loss: 243.7318    lr: 5.34351e-05\n",
      "Epoch:[ 0 | 29 ]    Batch:[ 80 | 130 ]    loss_giou: 14.6426    loss_conf: 144.5774    loss_cls: 61.5647    loss: 220.7846    lr: 6.10687e-05\n",
      "Epoch:[ 0 | 29 ]    Batch:[ 90 | 130 ]    loss_giou: 14.2679    loss_conf: 129.6415    loss_cls: 58.4129    loss: 202.3223    lr: 6.87023e-05\n",
      "Epoch:[ 0 | 29 ]    Batch:[ 100 | 130 ]    loss_giou: 13.9293    loss_conf: 117.5222    loss_cls: 55.7797    loss: 187.2312    lr: 7.63359e-05\n",
      "Epoch:[ 0 | 29 ]    Batch:[ 110 | 130 ]    loss_giou: 13.6407    loss_conf: 107.5663    loss_cls: 53.5184    loss: 174.7254    lr: 8.39695e-05\n",
      "Epoch:[ 0 | 29 ]    Batch:[ 120 | 130 ]    loss_giou: 13.3620    loss_conf: 99.1378    loss_cls: 51.5561    loss: 164.0558    lr: 9.16031e-05\n",
      "Epoch:[ 0 | 29 ]    Batch:[ 130 | 130 ]    loss_giou: 13.1408    loss_conf: 92.0670    loss_cls: 49.9108    loss: 155.1185    lr: 9.92366e-05\n",
      "save model:  ./weight/best.pt\n",
      "Epoch:[ 1 | 29 ]    Batch:[ 0 | 130 ]    loss_giou: 11.2027    loss_conf: 7.0923    loss_cls: 29.3682    loss: 47.6632    lr: 0.0001\n",
      "Epoch:[ 1 | 29 ]    Batch:[ 10 | 130 ]    loss_giou: 10.2273    loss_conf: 5.8311    loss_cls: 29.3536    loss: 45.4121    lr: 9.99983e-05\n",
      "Epoch:[ 1 | 29 ]    Batch:[ 20 | 130 ]    loss_giou: 10.5030    loss_conf: 5.7133    loss_cls: 29.3897    loss: 45.6060    lr: 9.99932e-05\n",
      "Epoch:[ 1 | 29 ]    Batch:[ 30 | 130 ]    loss_giou: 10.7478    loss_conf: 5.5344    loss_cls: 29.2304    loss: 45.5126    lr: 9.99848e-05\n",
      "Epoch:[ 1 | 29 ]    Batch:[ 40 | 130 ]    loss_giou: 10.6292    loss_conf: 5.3393    loss_cls: 28.9572    loss: 44.9257    lr: 9.99729e-05\n",
      "Epoch:[ 1 | 29 ]    Batch:[ 50 | 130 ]    loss_giou: 10.4168    loss_conf: 5.2379    loss_cls: 28.8515    loss: 44.5063    lr: 9.99577e-05\n",
      "Epoch:[ 1 | 29 ]    Batch:[ 60 | 130 ]    loss_giou: 10.3342    loss_conf: 5.0955    loss_cls: 28.7684    loss: 44.1982    lr: 9.99391e-05\n",
      "Epoch:[ 1 | 29 ]    Batch:[ 70 | 130 ]    loss_giou: 10.2215    loss_conf: 5.0403    loss_cls: 28.7136    loss: 43.9753    lr: 9.99171e-05\n",
      "Epoch:[ 1 | 29 ]    Batch:[ 80 | 130 ]    loss_giou: 10.0778    loss_conf: 4.9504    loss_cls: 28.6431    loss: 43.6713    lr: 9.98917e-05\n",
      "Epoch:[ 1 | 29 ]    Batch:[ 90 | 130 ]    loss_giou: 9.9527    loss_conf: 4.9101    loss_cls: 28.5396    loss: 43.4024    lr: 9.9863e-05\n",
      "Epoch:[ 1 | 29 ]    Batch:[ 100 | 130 ]    loss_giou: 9.8678    loss_conf: 4.8309    loss_cls: 28.4543    loss: 43.1530    lr: 9.98308e-05\n",
      "Epoch:[ 1 | 29 ]    Batch:[ 110 | 130 ]    loss_giou: 9.7979    loss_conf: 4.7309    loss_cls: 28.4092    loss: 42.9380    lr: 9.97953e-05\n",
      "Epoch:[ 1 | 29 ]    Batch:[ 120 | 130 ]    loss_giou: 9.7534    loss_conf: 4.6343    loss_cls: 28.2931    loss: 42.6808    lr: 9.97565e-05\n",
      "Epoch:[ 1 | 29 ]    Batch:[ 130 | 130 ]    loss_giou: 9.7116    loss_conf: 4.6059    loss_cls: 28.2522    loss: 42.5697    lr: 9.97142e-05\n",
      "save model:  ./weight/best.pt\n",
      "Epoch:[ 2 | 29 ]    Batch:[ 0 | 130 ]    loss_giou: 9.1863    loss_conf: 3.2313    loss_cls: 26.6483    loss: 39.0659    lr: 9.97098e-05\n",
      "Epoch:[ 2 | 29 ]    Batch:[ 10 | 130 ]    loss_giou: 8.4118    loss_conf: 3.6683    loss_cls: 27.1147    loss: 39.1947    lr: 9.96639e-05\n",
      "Epoch:[ 2 | 29 ]    Batch:[ 20 | 130 ]    loss_giou: 8.4116    loss_conf: 3.6146    loss_cls: 27.3782    loss: 39.4044    lr: 9.96146e-05\n",
      "Epoch:[ 2 | 29 ]    Batch:[ 30 | 130 ]    loss_giou: 8.3104    loss_conf: 3.6187    loss_cls: 27.2456    loss: 39.1746    lr: 9.95619e-05\n",
      "Epoch:[ 2 | 29 ]    Batch:[ 40 | 130 ]    loss_giou: 8.3464    loss_conf: 3.6527    loss_cls: 27.1348    loss: 39.1339    lr: 9.95059e-05\n",
      "Epoch:[ 2 | 29 ]    Batch:[ 50 | 130 ]    loss_giou: 8.5020    loss_conf: 3.6351    loss_cls: 27.0316    loss: 39.1687    lr: 9.94465e-05\n",
      "Epoch:[ 2 | 29 ]    Batch:[ 60 | 130 ]    loss_giou: 8.5982    loss_conf: 3.6018    loss_cls: 26.9186    loss: 39.1186    lr: 9.93838e-05\n",
      "Epoch:[ 2 | 29 ]    Batch:[ 70 | 130 ]    loss_giou: 8.5349    loss_conf: 3.4970    loss_cls: 26.8448    loss: 38.8767    lr: 9.93178e-05\n",
      "Epoch:[ 2 | 29 ]    Batch:[ 80 | 130 ]    loss_giou: 8.5301    loss_conf: 3.4804    loss_cls: 26.7849    loss: 38.7955    lr: 9.92484e-05\n",
      "Epoch:[ 2 | 29 ]    Batch:[ 90 | 130 ]    loss_giou: 8.5658    loss_conf: 3.4920    loss_cls: 26.7766    loss: 38.8343    lr: 9.91756e-05\n",
      "Epoch:[ 2 | 29 ]    Batch:[ 100 | 130 ]    loss_giou: 8.5587    loss_conf: 3.4878    loss_cls: 26.6865    loss: 38.7329    lr: 9.90996e-05\n",
      "Epoch:[ 2 | 29 ]    Batch:[ 110 | 130 ]    loss_giou: 8.5411    loss_conf: 3.4599    loss_cls: 26.6308    loss: 38.6319    lr: 9.90202e-05\n",
      "Epoch:[ 2 | 29 ]    Batch:[ 120 | 130 ]    loss_giou: 8.4821    loss_conf: 3.4467    loss_cls: 26.4840    loss: 38.4128    lr: 9.89375e-05\n",
      "Epoch:[ 2 | 29 ]    Batch:[ 130 | 130 ]    loss_giou: 8.4985    loss_conf: 3.4726    loss_cls: 26.2684    loss: 38.2394    lr: 9.88515e-05\n",
      "save model:  ./weight/best.pt\n",
      "Epoch:[ 3 | 29 ]    Batch:[ 0 | 130 ]    loss_giou: 7.5033    loss_conf: 3.0033    loss_cls: 26.1098    loss: 36.6164    lr: 9.88427e-05\n",
      "Epoch:[ 3 | 29 ]    Batch:[ 10 | 130 ]    loss_giou: 8.1087    loss_conf: 3.3061    loss_cls: 22.5624    loss: 33.9772    lr: 9.87531e-05\n",
      "Epoch:[ 3 | 29 ]    Batch:[ 20 | 130 ]    loss_giou: 8.2125    loss_conf: 3.3909    loss_cls: 22.1787    loss: 33.7821    lr: 9.86601e-05\n",
      "Epoch:[ 3 | 29 ]    Batch:[ 30 | 130 ]    loss_giou: 8.0584    loss_conf: 3.3895    loss_cls: 21.9277    loss: 33.3756    lr: 9.85639e-05\n",
      "Epoch:[ 3 | 29 ]    Batch:[ 40 | 130 ]    loss_giou: 8.0603    loss_conf: 3.4208    loss_cls: 21.4029    loss: 32.8840    lr: 9.84644e-05\n",
      "Epoch:[ 3 | 29 ]    Batch:[ 50 | 130 ]    loss_giou: 8.0867    loss_conf: 3.4231    loss_cls: 20.6570    loss: 32.1668    lr: 9.83615e-05\n",
      "Epoch:[ 3 | 29 ]    Batch:[ 60 | 130 ]    loss_giou: 8.1340    loss_conf: 3.4511    loss_cls: 19.9202    loss: 31.5053    lr: 9.82555e-05\n",
      "Epoch:[ 3 | 29 ]    Batch:[ 70 | 130 ]    loss_giou: 8.1202    loss_conf: 3.5377    loss_cls: 19.0242    loss: 30.6820    lr: 9.81461e-05\n",
      "Epoch:[ 3 | 29 ]    Batch:[ 80 | 130 ]    loss_giou: 8.0883    loss_conf: 3.6438    loss_cls: 18.4344    loss: 30.1665    lr: 9.80335e-05\n",
      "Epoch:[ 3 | 29 ]    Batch:[ 90 | 130 ]    loss_giou: 8.1023    loss_conf: 3.6191    loss_cls: 17.8907    loss: 29.6120    lr: 9.79177e-05\n",
      "Epoch:[ 3 | 29 ]    Batch:[ 100 | 130 ]    loss_giou: 8.1244    loss_conf: 3.6485    loss_cls: 17.2493    loss: 29.0222    lr: 9.77986e-05\n",
      "Epoch:[ 3 | 29 ]    Batch:[ 110 | 130 ]    loss_giou: 8.1637    loss_conf: 3.6869    loss_cls: 16.8861    loss: 28.7367    lr: 9.76762e-05\n",
      "Epoch:[ 3 | 29 ]    Batch:[ 120 | 130 ]    loss_giou: 8.1871    loss_conf: 3.7037    loss_cls: 16.3956    loss: 28.2864    lr: 9.75507e-05\n",
      "Epoch:[ 3 | 29 ]    Batch:[ 130 | 130 ]    loss_giou: 8.2561    loss_conf: 3.6984    loss_cls: 15.9768    loss: 27.9314    lr: 9.74219e-05\n",
      "save model:  ./weight/best.pt\n",
      "Epoch:[ 4 | 29 ]    Batch:[ 0 | 130 ]    loss_giou: 9.1910    loss_conf: 5.2382    loss_cls: 12.8807    loss: 27.3099    lr: 9.74088e-05\n",
      "Epoch:[ 4 | 29 ]    Batch:[ 10 | 130 ]    loss_giou: 8.7151    loss_conf: 3.8523    loss_cls: 11.8330    loss: 24.4004    lr: 9.72765e-05\n",
      "Epoch:[ 4 | 29 ]    Batch:[ 20 | 130 ]    loss_giou: 8.7347    loss_conf: 3.8773    loss_cls: 11.3182    loss: 23.9302    lr: 9.7141e-05\n",
      "Epoch:[ 4 | 29 ]    Batch:[ 30 | 130 ]    loss_giou: 8.6836    loss_conf: 3.8386    loss_cls: 10.8378    loss: 23.3600    lr: 9.70023e-05\n",
      "Epoch:[ 4 | 29 ]    Batch:[ 40 | 130 ]    loss_giou: 8.6197    loss_conf: 3.7227    loss_cls: 10.3840    loss: 22.7264    lr: 9.68605e-05\n",
      "Epoch:[ 4 | 29 ]    Batch:[ 50 | 130 ]    loss_giou: 8.4794    loss_conf: 3.6021    loss_cls: 10.0583    loss: 22.1398    lr: 9.67154e-05\n",
      "Epoch:[ 4 | 29 ]    Batch:[ 60 | 130 ]    loss_giou: 8.4429    loss_conf: 3.5489    loss_cls: 10.1522    loss: 22.1440    lr: 9.65672e-05\n",
      "Epoch:[ 4 | 29 ]    Batch:[ 70 | 130 ]    loss_giou: 8.3899    loss_conf: 3.5112    loss_cls: 9.9017    loss: 21.8028    lr: 9.64158e-05\n",
      "Epoch:[ 4 | 29 ]    Batch:[ 80 | 130 ]    loss_giou: 8.3858    loss_conf: 3.4771    loss_cls: 9.9621    loss: 21.8251    lr: 9.62614e-05\n",
      "Epoch:[ 4 | 29 ]    Batch:[ 90 | 130 ]    loss_giou: 8.3825    loss_conf: 3.5002    loss_cls: 9.9284    loss: 21.8111    lr: 9.61037e-05\n",
      "Epoch:[ 4 | 29 ]    Batch:[ 100 | 130 ]    loss_giou: 8.3648    loss_conf: 3.5395    loss_cls: 9.8902    loss: 21.7945    lr: 9.5943e-05\n",
      "Epoch:[ 4 | 29 ]    Batch:[ 110 | 130 ]    loss_giou: 8.3595    loss_conf: 3.5210    loss_cls: 9.9109    loss: 21.7914    lr: 9.57791e-05\n",
      "Epoch:[ 4 | 29 ]    Batch:[ 120 | 130 ]    loss_giou: 8.3283    loss_conf: 3.5147    loss_cls: 9.8395    loss: 21.6825    lr: 9.56122e-05\n",
      "Epoch:[ 4 | 29 ]    Batch:[ 130 | 130 ]    loss_giou: 8.2901    loss_conf: 3.4626    loss_cls: 9.8322    loss: 21.5849    lr: 9.54422e-05\n",
      "save model:  ./weight/best.pt\n",
      "Epoch:[ 5 | 29 ]    Batch:[ 0 | 130 ]    loss_giou: 7.4231    loss_conf: 3.1189    loss_cls: 6.9324    loss: 17.4743    lr: 9.5425e-05\n",
      "Epoch:[ 5 | 29 ]    Batch:[ 10 | 130 ]    loss_giou: 7.9357    loss_conf: 2.9928    loss_cls: 8.9801    loss: 19.9086    lr: 9.52516e-05\n",
      "Epoch:[ 5 | 29 ]    Batch:[ 20 | 130 ]    loss_giou: 8.0469    loss_conf: 3.0876    loss_cls: 8.2669    loss: 19.4013    lr: 9.50751e-05\n",
      "Epoch:[ 5 | 29 ]    Batch:[ 30 | 130 ]    loss_giou: 7.9547    loss_conf: 3.1303    loss_cls: 8.3756    loss: 19.4606    lr: 9.48956e-05\n",
      "Epoch:[ 5 | 29 ]    Batch:[ 40 | 130 ]    loss_giou: 7.9190    loss_conf: 3.1495    loss_cls: 8.6071    loss: 19.6757    lr: 9.4713e-05\n",
      "Epoch:[ 5 | 29 ]    Batch:[ 50 | 130 ]    loss_giou: 7.9076    loss_conf: 3.1510    loss_cls: 8.4385    loss: 19.4971    lr: 9.45274e-05\n",
      "Epoch:[ 5 | 29 ]    Batch:[ 60 | 130 ]    loss_giou: 7.8682    loss_conf: 3.0765    loss_cls: 8.4783    loss: 19.4230    lr: 9.43388e-05\n",
      "Epoch:[ 5 | 29 ]    Batch:[ 70 | 130 ]    loss_giou: 7.8271    loss_conf: 3.0121    loss_cls: 8.4548    loss: 19.2940    lr: 9.41473e-05\n",
      "Epoch:[ 5 | 29 ]    Batch:[ 80 | 130 ]    loss_giou: 7.7859    loss_conf: 3.0128    loss_cls: 8.2947    loss: 19.0933    lr: 9.39527e-05\n",
      "Epoch:[ 5 | 29 ]    Batch:[ 90 | 130 ]    loss_giou: 7.7489    loss_conf: 2.9961    loss_cls: 8.1906    loss: 18.9355    lr: 9.37551e-05\n",
      "Epoch:[ 5 | 29 ]    Batch:[ 100 | 130 ]    loss_giou: 7.7093    loss_conf: 2.9819    loss_cls: 8.0410    loss: 18.7323    lr: 9.35546e-05\n",
      "Epoch:[ 5 | 29 ]    Batch:[ 110 | 130 ]    loss_giou: 7.6801    loss_conf: 2.9854    loss_cls: 7.8562    loss: 18.5217    lr: 9.33512e-05\n",
      "Epoch:[ 5 | 29 ]    Batch:[ 120 | 130 ]    loss_giou: 7.6679    loss_conf: 2.9774    loss_cls: 7.8730    loss: 18.5183    lr: 9.31448e-05\n",
      "Epoch:[ 5 | 29 ]    Batch:[ 130 | 130 ]    loss_giou: 7.6772    loss_conf: 2.9724    loss_cls: 7.8001    loss: 18.4496    lr: 9.29355e-05\n",
      "save model:  ./weight/best.pt\n",
      "Epoch:[ 6 | 29 ]    Batch:[ 0 | 130 ]    loss_giou: 8.0316    loss_conf: 3.1912    loss_cls: 7.8802    loss: 19.1030    lr: 9.29144e-05\n",
      "Epoch:[ 6 | 29 ]    Batch:[ 10 | 130 ]    loss_giou: 7.4932    loss_conf: 2.7956    loss_cls: 6.8209    loss: 17.1098    lr: 9.27019e-05\n",
      "Epoch:[ 6 | 29 ]    Batch:[ 20 | 130 ]    loss_giou: 7.6485    loss_conf: 2.9317    loss_cls: 7.8053    loss: 18.3855    lr: 9.24866e-05\n",
      "Epoch:[ 6 | 29 ]    Batch:[ 30 | 130 ]    loss_giou: 7.7373    loss_conf: 2.8662    loss_cls: 8.1853    loss: 18.7888    lr: 9.22683e-05\n",
      "Epoch:[ 6 | 29 ]    Batch:[ 40 | 130 ]    loss_giou: 7.5941    loss_conf: 2.7592    loss_cls: 8.2861    loss: 18.6394    lr: 9.20472e-05\n",
      "Epoch:[ 6 | 29 ]    Batch:[ 50 | 130 ]    loss_giou: 7.5121    loss_conf: 2.7673    loss_cls: 8.5062    loss: 18.7856    lr: 9.18233e-05\n",
      "Epoch:[ 6 | 29 ]    Batch:[ 60 | 130 ]    loss_giou: 7.4278    loss_conf: 2.7453    loss_cls: 8.4257    loss: 18.5987    lr: 9.15965e-05\n",
      "Epoch:[ 6 | 29 ]    Batch:[ 70 | 130 ]    loss_giou: 7.3892    loss_conf: 2.7155    loss_cls: 8.6623    loss: 18.7670    lr: 9.13669e-05\n",
      "Epoch:[ 6 | 29 ]    Batch:[ 80 | 130 ]    loss_giou: 7.3624    loss_conf: 2.7131    loss_cls: 8.5176    loss: 18.5931    lr: 9.11346e-05\n",
      "Epoch:[ 6 | 29 ]    Batch:[ 90 | 130 ]    loss_giou: 7.3500    loss_conf: 2.6905    loss_cls: 8.4250    loss: 18.4655    lr: 9.08994e-05\n",
      "Epoch:[ 6 | 29 ]    Batch:[ 100 | 130 ]    loss_giou: 7.3701    loss_conf: 2.6578    loss_cls: 8.3824    loss: 18.4103    lr: 9.06615e-05\n",
      "Epoch:[ 6 | 29 ]    Batch:[ 110 | 130 ]    loss_giou: 7.3788    loss_conf: 2.6326    loss_cls: 8.2612    loss: 18.2726    lr: 9.04209e-05\n",
      "Epoch:[ 6 | 29 ]    Batch:[ 120 | 130 ]    loss_giou: 7.3327    loss_conf: 2.6402    loss_cls: 8.2124    loss: 18.1853    lr: 9.01775e-05\n",
      "Epoch:[ 6 | 29 ]    Batch:[ 130 | 130 ]    loss_giou: 7.3030    loss_conf: 2.6201    loss_cls: 8.0188    loss: 17.9419    lr: 8.99314e-05\n",
      "save model:  ./weight/best.pt\n",
      "Epoch:[ 7 | 29 ]    Batch:[ 0 | 130 ]    loss_giou: 7.0200    loss_conf: 2.7635    loss_cls: 3.9781    loss: 13.7616    lr: 8.99066e-05\n",
      "Epoch:[ 7 | 29 ]    Batch:[ 10 | 130 ]    loss_giou: 7.2124    loss_conf: 2.3900    loss_cls: 7.3091    loss: 16.9114    lr: 8.96575e-05\n",
      "Epoch:[ 7 | 29 ]    Batch:[ 20 | 130 ]    loss_giou: 7.1817    loss_conf: 2.3264    loss_cls: 7.1335    loss: 16.6417    lr: 8.94058e-05\n",
      "Epoch:[ 7 | 29 ]    Batch:[ 30 | 130 ]    loss_giou: 7.1912    loss_conf: 2.3882    loss_cls: 7.4615    loss: 17.0409    lr: 8.91514e-05\n",
      "Epoch:[ 7 | 29 ]    Batch:[ 40 | 130 ]    loss_giou: 7.2084    loss_conf: 2.4465    loss_cls: 7.5441    loss: 17.1991    lr: 8.88943e-05\n",
      "Epoch:[ 7 | 29 ]    Batch:[ 50 | 130 ]    loss_giou: 7.1955    loss_conf: 2.4066    loss_cls: 7.4134    loss: 17.0155    lr: 8.86347e-05\n",
      "Epoch:[ 7 | 29 ]    Batch:[ 60 | 130 ]    loss_giou: 7.1798    loss_conf: 2.4059    loss_cls: 7.3250    loss: 16.9107    lr: 8.83724e-05\n",
      "Epoch:[ 7 | 29 ]    Batch:[ 70 | 130 ]    loss_giou: 7.2004    loss_conf: 2.3973    loss_cls: 7.1533    loss: 16.7511    lr: 8.81075e-05\n",
      "Epoch:[ 7 | 29 ]    Batch:[ 80 | 130 ]    loss_giou: 7.2272    loss_conf: 2.3760    loss_cls: 7.2999    loss: 16.9031    lr: 8.78401e-05\n",
      "Epoch:[ 7 | 29 ]    Batch:[ 90 | 130 ]    loss_giou: 7.2230    loss_conf: 2.3516    loss_cls: 7.3277    loss: 16.9023    lr: 8.75701e-05\n",
      "Epoch:[ 7 | 29 ]    Batch:[ 100 | 130 ]    loss_giou: 7.2332    loss_conf: 2.3736    loss_cls: 7.4625    loss: 17.0694    lr: 8.72975e-05\n",
      "Epoch:[ 7 | 29 ]    Batch:[ 110 | 130 ]    loss_giou: 7.2029    loss_conf: 2.3878    loss_cls: 7.3439    loss: 16.9347    lr: 8.70225e-05\n",
      "Epoch:[ 7 | 29 ]    Batch:[ 120 | 130 ]    loss_giou: 7.1891    loss_conf: 2.4057    loss_cls: 7.3579    loss: 16.9527    lr: 8.67449e-05\n",
      "Epoch:[ 7 | 29 ]    Batch:[ 130 | 130 ]    loss_giou: 7.1461    loss_conf: 2.4053    loss_cls: 7.3854    loss: 16.9369    lr: 8.64649e-05\n",
      "save model:  ./weight/best.pt\n",
      "Epoch:[ 8 | 29 ]    Batch:[ 0 | 130 ]    loss_giou: 6.7552    loss_conf: 2.9614    loss_cls: 4.3183    loss: 14.0349    lr: 8.64368e-05\n",
      "Epoch:[ 8 | 29 ]    Batch:[ 10 | 130 ]    loss_giou: 7.0419    loss_conf: 2.4796    loss_cls: 6.5240    loss: 16.0455    lr: 8.6154e-05\n",
      "Epoch:[ 8 | 29 ]    Batch:[ 20 | 130 ]    loss_giou: 7.0784    loss_conf: 2.3215    loss_cls: 6.3797    loss: 15.7797    lr: 8.58689e-05\n",
      "Epoch:[ 8 | 29 ]    Batch:[ 30 | 130 ]    loss_giou: 7.1402    loss_conf: 2.3082    loss_cls: 6.5827    loss: 16.0311    lr: 8.55813e-05\n",
      "Epoch:[ 8 | 29 ]    Batch:[ 40 | 130 ]    loss_giou: 7.0625    loss_conf: 2.3354    loss_cls: 6.5863    loss: 15.9842    lr: 8.52913e-05\n",
      "Epoch:[ 8 | 29 ]    Batch:[ 50 | 130 ]    loss_giou: 7.0419    loss_conf: 2.3421    loss_cls: 6.6580    loss: 16.0420    lr: 8.49989e-05\n",
      "Epoch:[ 8 | 29 ]    Batch:[ 60 | 130 ]    loss_giou: 7.0498    loss_conf: 2.3750    loss_cls: 6.6483    loss: 16.0731    lr: 8.47042e-05\n",
      "Epoch:[ 8 | 29 ]    Batch:[ 70 | 130 ]    loss_giou: 7.0009    loss_conf: 2.3982    loss_cls: 6.6410    loss: 16.0401    lr: 8.44072e-05\n",
      "Epoch:[ 8 | 29 ]    Batch:[ 80 | 130 ]    loss_giou: 7.0055    loss_conf: 2.3809    loss_cls: 6.6693    loss: 16.0557    lr: 8.41078e-05\n",
      "Epoch:[ 8 | 29 ]    Batch:[ 90 | 130 ]    loss_giou: 7.0130    loss_conf: 2.3543    loss_cls: 6.6064    loss: 15.9737    lr: 8.38061e-05\n",
      "Epoch:[ 8 | 29 ]    Batch:[ 100 | 130 ]    loss_giou: 7.0225    loss_conf: 2.3585    loss_cls: 6.6962    loss: 16.0772    lr: 8.35021e-05\n",
      "Epoch:[ 8 | 29 ]    Batch:[ 110 | 130 ]    loss_giou: 6.9907    loss_conf: 2.3578    loss_cls: 6.6198    loss: 15.9684    lr: 8.31959e-05\n",
      "Epoch:[ 8 | 29 ]    Batch:[ 120 | 130 ]    loss_giou: 7.0274    loss_conf: 2.3670    loss_cls: 6.6443    loss: 16.0387    lr: 8.28875e-05\n",
      "Epoch:[ 8 | 29 ]    Batch:[ 130 | 130 ]    loss_giou: 7.0383    loss_conf: 2.3321    loss_cls: 6.6114    loss: 15.9818    lr: 8.25768e-05\n",
      "save model:  ./weight/best.pt\n",
      "Epoch:[ 9 | 29 ]    Batch:[ 0 | 130 ]    loss_giou: 9.0169    loss_conf: 2.7755    loss_cls: 7.7204    loss: 19.5128    lr: 8.25456e-05\n",
      "Epoch:[ 9 | 29 ]    Batch:[ 10 | 130 ]    loss_giou: 7.3915    loss_conf: 2.2189    loss_cls: 5.9479    loss: 15.5582    lr: 8.22325e-05\n",
      "Epoch:[ 9 | 29 ]    Batch:[ 20 | 130 ]    loss_giou: 7.0438    loss_conf: 2.1036    loss_cls: 7.0647    loss: 16.2121    lr: 8.19173e-05\n",
      "Epoch:[ 9 | 29 ]    Batch:[ 30 | 130 ]    loss_giou: 6.8173    loss_conf: 2.0864    loss_cls: 6.6899    loss: 15.5937    lr: 8.15999e-05\n",
      "Epoch:[ 9 | 29 ]    Batch:[ 40 | 130 ]    loss_giou: 6.7514    loss_conf: 2.1350    loss_cls: 6.9588    loss: 15.8452    lr: 8.12804e-05\n",
      "Epoch:[ 9 | 29 ]    Batch:[ 50 | 130 ]    loss_giou: 6.7194    loss_conf: 2.1538    loss_cls: 6.8972    loss: 15.7705    lr: 8.09588e-05\n",
      "Epoch:[ 9 | 29 ]    Batch:[ 60 | 130 ]    loss_giou: 6.7494    loss_conf: 2.1922    loss_cls: 6.9238    loss: 15.8654    lr: 8.0635e-05\n",
      "Epoch:[ 9 | 29 ]    Batch:[ 70 | 130 ]    loss_giou: 6.7432    loss_conf: 2.1700    loss_cls: 6.6445    loss: 15.5577    lr: 8.03093e-05\n",
      "Epoch:[ 9 | 29 ]    Batch:[ 80 | 130 ]    loss_giou: 6.7183    loss_conf: 2.1794    loss_cls: 6.5752    loss: 15.4730    lr: 7.99815e-05\n",
      "Epoch:[ 9 | 29 ]    Batch:[ 90 | 130 ]    loss_giou: 6.6961    loss_conf: 2.1747    loss_cls: 6.4324    loss: 15.3032    lr: 7.96516e-05\n",
      "Epoch:[ 9 | 29 ]    Batch:[ 100 | 130 ]    loss_giou: 6.6764    loss_conf: 2.1506    loss_cls: 6.3758    loss: 15.2028    lr: 7.93198e-05\n",
      "Epoch:[ 9 | 29 ]    Batch:[ 110 | 130 ]    loss_giou: 6.6516    loss_conf: 2.1506    loss_cls: 6.3230    loss: 15.1252    lr: 7.8986e-05\n",
      "Epoch:[ 9 | 29 ]    Batch:[ 120 | 130 ]    loss_giou: 6.6429    loss_conf: 2.1523    loss_cls: 6.2549    loss: 15.0501    lr: 7.86503e-05\n",
      "Epoch:[ 9 | 29 ]    Batch:[ 130 | 130 ]    loss_giou: 6.6809    loss_conf: 2.1440    loss_cls: 6.2544    loss: 15.0793    lr: 7.83126e-05\n",
      "save model:  ./weight/best.pt\n",
      "Epoch:[ 10 | 29 ]    Batch:[ 0 | 130 ]    loss_giou: 7.3677    loss_conf: 1.6973    loss_cls: 3.5733    loss: 12.6383    lr: 7.82788e-05\n",
      "Epoch:[ 10 | 29 ]    Batch:[ 10 | 130 ]    loss_giou: 7.0679    loss_conf: 2.2414    loss_cls: 7.2212    loss: 16.5305    lr: 7.7939e-05\n",
      "Epoch:[ 10 | 29 ]    Batch:[ 20 | 130 ]    loss_giou: 6.9033    loss_conf: 2.1050    loss_cls: 7.3154    loss: 16.3236    lr: 7.75974e-05\n",
      "Epoch:[ 10 | 29 ]    Batch:[ 30 | 130 ]    loss_giou: 6.8322    loss_conf: 2.0999    loss_cls: 6.9423    loss: 15.8743    lr: 7.72539e-05\n",
      "Epoch:[ 10 | 29 ]    Batch:[ 40 | 130 ]    loss_giou: 6.7120    loss_conf: 2.1003    loss_cls: 6.7256    loss: 15.5379    lr: 7.69086e-05\n",
      "Epoch:[ 10 | 29 ]    Batch:[ 50 | 130 ]    loss_giou: 6.6672    loss_conf: 2.1565    loss_cls: 6.6573    loss: 15.4810    lr: 7.65615e-05\n",
      "Epoch:[ 10 | 29 ]    Batch:[ 60 | 130 ]    loss_giou: 6.6447    loss_conf: 2.1445    loss_cls: 6.6517    loss: 15.4410    lr: 7.62126e-05\n",
      "Epoch:[ 10 | 29 ]    Batch:[ 70 | 130 ]    loss_giou: 6.6583    loss_conf: 2.1336    loss_cls: 6.6605    loss: 15.4523    lr: 7.58619e-05\n",
      "Epoch:[ 10 | 29 ]    Batch:[ 80 | 130 ]    loss_giou: 6.6549    loss_conf: 2.1203    loss_cls: 6.5743    loss: 15.3495    lr: 7.55095e-05\n",
      "Epoch:[ 10 | 29 ]    Batch:[ 90 | 130 ]    loss_giou: 6.6296    loss_conf: 2.1306    loss_cls: 6.4712    loss: 15.2314    lr: 7.51554e-05\n",
      "Epoch:[ 10 | 29 ]    Batch:[ 100 | 130 ]    loss_giou: 6.6289    loss_conf: 2.1282    loss_cls: 6.4643    loss: 15.2215    lr: 7.47996e-05\n",
      "Epoch:[ 10 | 29 ]    Batch:[ 110 | 130 ]    loss_giou: 6.6178    loss_conf: 2.1345    loss_cls: 6.4557    loss: 15.2080    lr: 7.44422e-05\n",
      "Epoch:[ 10 | 29 ]    Batch:[ 120 | 130 ]    loss_giou: 6.5983    loss_conf: 2.1135    loss_cls: 6.3318    loss: 15.0436    lr: 7.40831e-05\n",
      "Epoch:[ 10 | 29 ]    Batch:[ 130 | 130 ]    loss_giou: 6.5974    loss_conf: 2.0927    loss_cls: 6.3637    loss: 15.0538    lr: 7.37224e-05\n",
      "save model:  ./weight/best.pt\n",
      "Epoch:[ 11 | 29 ]    Batch:[ 0 | 130 ]    loss_giou: 6.3353    loss_conf: 1.7547    loss_cls: 6.8240    loss: 14.9139    lr: 7.36862e-05\n",
      "Epoch:[ 11 | 29 ]    Batch:[ 10 | 130 ]    loss_giou: 6.2659    loss_conf: 2.0636    loss_cls: 6.6171    loss: 14.9466    lr: 7.33238e-05\n",
      "Epoch:[ 11 | 29 ]    Batch:[ 20 | 130 ]    loss_giou: 6.4052    loss_conf: 1.9793    loss_cls: 6.1821    loss: 14.5666    lr: 7.29598e-05\n",
      "Epoch:[ 11 | 29 ]    Batch:[ 30 | 130 ]    loss_giou: 6.3625    loss_conf: 1.9701    loss_cls: 6.0542    loss: 14.3868    lr: 7.25942e-05\n",
      "Epoch:[ 11 | 29 ]    Batch:[ 40 | 130 ]    loss_giou: 6.3608    loss_conf: 1.9903    loss_cls: 6.1000    loss: 14.4511    lr: 7.22272e-05\n",
      "Epoch:[ 11 | 29 ]    Batch:[ 50 | 130 ]    loss_giou: 6.3521    loss_conf: 1.9343    loss_cls: 6.2131    loss: 14.4995    lr: 7.18586e-05\n",
      "Epoch:[ 11 | 29 ]    Batch:[ 60 | 130 ]    loss_giou: 6.3542    loss_conf: 1.9546    loss_cls: 6.2639    loss: 14.5728    lr: 7.14886e-05\n",
      "Epoch:[ 11 | 29 ]    Batch:[ 70 | 130 ]    loss_giou: 6.3615    loss_conf: 1.9629    loss_cls: 6.2840    loss: 14.6084    lr: 7.11172e-05\n",
      "Epoch:[ 11 | 29 ]    Batch:[ 80 | 130 ]    loss_giou: 6.3795    loss_conf: 1.9944    loss_cls: 6.0461    loss: 14.4200    lr: 7.07443e-05\n",
      "Epoch:[ 11 | 29 ]    Batch:[ 90 | 130 ]    loss_giou: 6.4191    loss_conf: 1.9957    loss_cls: 6.0321    loss: 14.4469    lr: 7.03701e-05\n",
      "Epoch:[ 11 | 29 ]    Batch:[ 100 | 130 ]    loss_giou: 6.4263    loss_conf: 1.9858    loss_cls: 6.1280    loss: 14.5402    lr: 6.99945e-05\n",
      "Epoch:[ 11 | 29 ]    Batch:[ 110 | 130 ]    loss_giou: 6.4513    loss_conf: 2.0050    loss_cls: 6.1582    loss: 14.6145    lr: 6.96176e-05\n",
      "Epoch:[ 11 | 29 ]    Batch:[ 120 | 130 ]    loss_giou: 6.4666    loss_conf: 2.0105    loss_cls: 6.1057    loss: 14.5828    lr: 6.92394e-05\n",
      "Epoch:[ 11 | 29 ]    Batch:[ 130 | 130 ]    loss_giou: 6.4497    loss_conf: 1.9933    loss_cls: 5.9985    loss: 14.4414    lr: 6.88599e-05\n",
      "save model:  ./weight/best.pt\n",
      "Epoch:[ 12 | 29 ]    Batch:[ 0 | 130 ]    loss_giou: 6.3991    loss_conf: 2.1933    loss_cls: 10.5496    loss: 19.1420    lr: 6.88218e-05\n",
      "Epoch:[ 12 | 29 ]    Batch:[ 10 | 130 ]    loss_giou: 6.0878    loss_conf: 1.9656    loss_cls: 5.9363    loss: 13.9898    lr: 6.84409e-05\n",
      "Epoch:[ 12 | 29 ]    Batch:[ 20 | 130 ]    loss_giou: 6.1979    loss_conf: 2.0645    loss_cls: 6.2988    loss: 14.5612    lr: 6.80588e-05\n",
      "Epoch:[ 12 | 29 ]    Batch:[ 30 | 130 ]    loss_giou: 6.2232    loss_conf: 1.9311    loss_cls: 6.0683    loss: 14.2226    lr: 6.76755e-05\n",
      "Epoch:[ 12 | 29 ]    Batch:[ 40 | 130 ]    loss_giou: 6.2280    loss_conf: 1.9398    loss_cls: 6.1757    loss: 14.3435    lr: 6.7291e-05\n",
      "Epoch:[ 12 | 29 ]    Batch:[ 50 | 130 ]    loss_giou: 6.2365    loss_conf: 1.9303    loss_cls: 6.1602    loss: 14.3270    lr: 6.69054e-05\n",
      "Epoch:[ 12 | 29 ]    Batch:[ 60 | 130 ]    loss_giou: 6.2932    loss_conf: 1.9439    loss_cls: 5.9647    loss: 14.2018    lr: 6.65186e-05\n",
      "Epoch:[ 12 | 29 ]    Batch:[ 70 | 130 ]    loss_giou: 6.3072    loss_conf: 1.9908    loss_cls: 6.0006    loss: 14.2986    lr: 6.61308e-05\n",
      "Epoch:[ 12 | 29 ]    Batch:[ 80 | 130 ]    loss_giou: 6.2733    loss_conf: 1.9702    loss_cls: 5.9192    loss: 14.1627    lr: 6.57418e-05\n",
      "Epoch:[ 12 | 29 ]    Batch:[ 90 | 130 ]    loss_giou: 6.2622    loss_conf: 1.9586    loss_cls: 6.0297    loss: 14.2505    lr: 6.53519e-05\n",
      "Epoch:[ 12 | 29 ]    Batch:[ 100 | 130 ]    loss_giou: 6.2516    loss_conf: 1.9894    loss_cls: 5.9668    loss: 14.2078    lr: 6.49609e-05\n",
      "Epoch:[ 12 | 29 ]    Batch:[ 110 | 130 ]    loss_giou: 6.2449    loss_conf: 1.9749    loss_cls: 5.9753    loss: 14.1951    lr: 6.45689e-05\n",
      "Epoch:[ 12 | 29 ]    Batch:[ 120 | 130 ]    loss_giou: 6.2188    loss_conf: 1.9573    loss_cls: 5.8778    loss: 14.0539    lr: 6.4176e-05\n",
      "Epoch:[ 12 | 29 ]    Batch:[ 130 | 130 ]    loss_giou: 6.2103    loss_conf: 1.9494    loss_cls: 5.8319    loss: 13.9916    lr: 6.37821e-05\n",
      "save model:  ./weight/best.pt\n",
      "Epoch:[ 13 | 29 ]    Batch:[ 0 | 130 ]    loss_giou: 6.7469    loss_conf: 1.8982    loss_cls: 9.6453    loss: 18.2903    lr: 6.37427e-05\n",
      "Epoch:[ 13 | 29 ]    Batch:[ 10 | 130 ]    loss_giou: 6.1023    loss_conf: 1.7762    loss_cls: 5.2658    loss: 13.1442    lr: 6.33478e-05\n",
      "Epoch:[ 13 | 29 ]    Batch:[ 20 | 130 ]    loss_giou: 6.0696    loss_conf: 1.7305    loss_cls: 5.7072    loss: 13.5073    lr: 6.2952e-05\n",
      "Epoch:[ 13 | 29 ]    Batch:[ 30 | 130 ]    loss_giou: 6.0686    loss_conf: 1.8142    loss_cls: 6.1477    loss: 14.0305    lr: 6.25554e-05\n",
      "Epoch:[ 13 | 29 ]    Batch:[ 40 | 130 ]    loss_giou: 6.0671    loss_conf: 1.8134    loss_cls: 5.8854    loss: 13.7659    lr: 6.2158e-05\n",
      "Epoch:[ 13 | 29 ]    Batch:[ 50 | 130 ]    loss_giou: 6.0925    loss_conf: 1.8785    loss_cls: 6.0579    loss: 14.0288    lr: 6.17598e-05\n",
      "Epoch:[ 13 | 29 ]    Batch:[ 60 | 130 ]    loss_giou: 6.0936    loss_conf: 1.8840    loss_cls: 5.9458    loss: 13.9234    lr: 6.13608e-05\n",
      "Epoch:[ 13 | 29 ]    Batch:[ 70 | 130 ]    loss_giou: 6.0921    loss_conf: 1.8681    loss_cls: 6.1487    loss: 14.1089    lr: 6.09611e-05\n",
      "Epoch:[ 13 | 29 ]    Batch:[ 80 | 130 ]    loss_giou: 6.1126    loss_conf: 1.8899    loss_cls: 6.1853    loss: 14.1878    lr: 6.05606e-05\n",
      "Epoch:[ 13 | 29 ]    Batch:[ 90 | 130 ]    loss_giou: 6.1133    loss_conf: 1.8871    loss_cls: 6.3060    loss: 14.3064    lr: 6.01595e-05\n",
      "Epoch:[ 13 | 29 ]    Batch:[ 100 | 130 ]    loss_giou: 6.1169    loss_conf: 1.8876    loss_cls: 6.2041    loss: 14.2086    lr: 5.97577e-05\n",
      "Epoch:[ 13 | 29 ]    Batch:[ 110 | 130 ]    loss_giou: 6.1522    loss_conf: 1.8864    loss_cls: 6.1609    loss: 14.1995    lr: 5.93553e-05\n",
      "Epoch:[ 13 | 29 ]    Batch:[ 120 | 130 ]    loss_giou: 6.1659    loss_conf: 1.8945    loss_cls: 6.0441    loss: 14.1045    lr: 5.89522e-05\n",
      "Epoch:[ 13 | 29 ]    Batch:[ 130 | 130 ]    loss_giou: 6.1638    loss_conf: 1.9066    loss_cls: 5.9522    loss: 14.0225    lr: 5.85486e-05\n",
      "save model:  ./weight/best.pt\n",
      "Epoch:[ 14 | 29 ]    Batch:[ 0 | 130 ]    loss_giou: 5.9843    loss_conf: 1.8898    loss_cls: 9.9522    loss: 17.8263    lr: 5.85082e-05\n",
      "Epoch:[ 14 | 29 ]    Batch:[ 10 | 130 ]    loss_giou: 5.8659    loss_conf: 1.7192    loss_cls: 5.2314    loss: 12.8166    lr: 5.8104e-05\n",
      "Epoch:[ 14 | 29 ]    Batch:[ 20 | 130 ]    loss_giou: 5.8926    loss_conf: 1.8983    loss_cls: 6.0600    loss: 13.8509    lr: 5.76993e-05\n",
      "Epoch:[ 14 | 29 ]    Batch:[ 30 | 130 ]    loss_giou: 5.9458    loss_conf: 1.9533    loss_cls: 6.2556    loss: 14.1547    lr: 5.7294e-05\n",
      "Epoch:[ 14 | 29 ]    Batch:[ 40 | 130 ]    loss_giou: 5.9900    loss_conf: 1.9176    loss_cls: 6.0253    loss: 13.9328    lr: 5.68883e-05\n",
      "Epoch:[ 14 | 29 ]    Batch:[ 50 | 130 ]    loss_giou: 5.9805    loss_conf: 1.8882    loss_cls: 5.9578    loss: 13.8265    lr: 5.64822e-05\n",
      "Epoch:[ 14 | 29 ]    Batch:[ 60 | 130 ]    loss_giou: 6.0070    loss_conf: 1.8491    loss_cls: 5.7655    loss: 13.6216    lr: 5.60757e-05\n",
      "Epoch:[ 14 | 29 ]    Batch:[ 70 | 130 ]    loss_giou: 6.0100    loss_conf: 1.8668    loss_cls: 5.6292    loss: 13.5059    lr: 5.56687e-05\n",
      "Epoch:[ 14 | 29 ]    Batch:[ 80 | 130 ]    loss_giou: 6.0051    loss_conf: 1.8743    loss_cls: 5.5922    loss: 13.4717    lr: 5.52615e-05\n",
      "Epoch:[ 14 | 29 ]    Batch:[ 90 | 130 ]    loss_giou: 6.0113    loss_conf: 1.8910    loss_cls: 5.5417    loss: 13.4440    lr: 5.48539e-05\n",
      "Epoch:[ 14 | 29 ]    Batch:[ 100 | 130 ]    loss_giou: 6.0066    loss_conf: 1.8904    loss_cls: 5.5717    loss: 13.4687    lr: 5.4446e-05\n",
      "Epoch:[ 14 | 29 ]    Batch:[ 110 | 130 ]    loss_giou: 6.0027    loss_conf: 1.8826    loss_cls: 5.6109    loss: 13.4963    lr: 5.40378e-05\n",
      "Epoch:[ 14 | 29 ]    Batch:[ 120 | 130 ]    loss_giou: 5.9892    loss_conf: 1.8654    loss_cls: 5.5207    loss: 13.3753    lr: 5.36294e-05\n",
      "Epoch:[ 14 | 29 ]    Batch:[ 130 | 130 ]    loss_giou: 5.9971    loss_conf: 1.8600    loss_cls: 5.5840    loss: 13.4411    lr: 5.32207e-05\n",
      "save model:  ./weight/best.pt\n",
      "Epoch:[ 15 | 29 ]    Batch:[ 0 | 130 ]    loss_giou: 6.0806    loss_conf: 1.4393    loss_cls: 6.9682    loss: 14.4881    lr: 5.31799e-05\n",
      "Epoch:[ 15 | 29 ]    Batch:[ 10 | 130 ]    loss_giou: 5.8601    loss_conf: 1.9660    loss_cls: 6.1606    loss: 13.9867    lr: 5.2771e-05\n",
      "Epoch:[ 15 | 29 ]    Batch:[ 20 | 130 ]    loss_giou: 5.9281    loss_conf: 1.9087    loss_cls: 5.5077    loss: 13.3445    lr: 5.23621e-05\n",
      "Epoch:[ 15 | 29 ]    Batch:[ 30 | 130 ]    loss_giou: 5.8962    loss_conf: 1.7618    loss_cls: 5.4142    loss: 13.0722    lr: 5.1953e-05\n",
      "Epoch:[ 15 | 29 ]    Batch:[ 40 | 130 ]    loss_giou: 5.9386    loss_conf: 1.8146    loss_cls: 5.5918    loss: 13.3450    lr: 5.15437e-05\n",
      "Epoch:[ 15 | 29 ]    Batch:[ 50 | 130 ]    loss_giou: 5.9643    loss_conf: 1.8306    loss_cls: 5.6982    loss: 13.4930    lr: 5.11345e-05\n",
      "Epoch:[ 15 | 29 ]    Batch:[ 60 | 130 ]    loss_giou: 5.9568    loss_conf: 1.8312    loss_cls: 5.5623    loss: 13.3503    lr: 5.07251e-05\n",
      "Epoch:[ 15 | 29 ]    Batch:[ 70 | 130 ]    loss_giou: 5.9438    loss_conf: 1.8452    loss_cls: 5.5098    loss: 13.2989    lr: 5.03158e-05\n",
      "Epoch:[ 15 | 29 ]    Batch:[ 80 | 130 ]    loss_giou: 5.9111    loss_conf: 1.8116    loss_cls: 5.4978    loss: 13.2205    lr: 4.99065e-05\n",
      "Epoch:[ 15 | 29 ]    Batch:[ 90 | 130 ]    loss_giou: 5.9363    loss_conf: 1.8103    loss_cls: 5.4809    loss: 13.2275    lr: 4.94972e-05\n",
      "Epoch:[ 15 | 29 ]    Batch:[ 100 | 130 ]    loss_giou: 5.9451    loss_conf: 1.7831    loss_cls: 5.4358    loss: 13.1640    lr: 4.9088e-05\n",
      "Epoch:[ 15 | 29 ]    Batch:[ 110 | 130 ]    loss_giou: 5.9356    loss_conf: 1.7912    loss_cls: 5.4793    loss: 13.2061    lr: 4.86788e-05\n",
      "Epoch:[ 15 | 29 ]    Batch:[ 120 | 130 ]    loss_giou: 5.9297    loss_conf: 1.7854    loss_cls: 5.5061    loss: 13.2212    lr: 4.82698e-05\n",
      "Epoch:[ 15 | 29 ]    Batch:[ 130 | 130 ]    loss_giou: 5.9150    loss_conf: 1.7853    loss_cls: 5.5436    loss: 13.2439    lr: 4.7861e-05\n",
      "save model:  ./weight/best.pt\n",
      "Epoch:[ 16 | 29 ]    Batch:[ 0 | 130 ]    loss_giou: 6.2872    loss_conf: 1.7998    loss_cls: 7.1365    loss: 15.2235    lr: 4.78201e-05\n",
      "Epoch:[ 16 | 29 ]    Batch:[ 10 | 130 ]    loss_giou: 5.8611    loss_conf: 1.7414    loss_cls: 5.9358    loss: 13.5384    lr: 4.74115e-05\n",
      "Epoch:[ 16 | 29 ]    Batch:[ 20 | 130 ]    loss_giou: 5.6670    loss_conf: 1.6000    loss_cls: 4.9380    loss: 12.2050    lr: 4.7003e-05\n",
      "Epoch:[ 16 | 29 ]    Batch:[ 30 | 130 ]    loss_giou: 5.7156    loss_conf: 1.5120    loss_cls: 4.7315    loss: 11.9591    lr: 4.65949e-05\n",
      "Epoch:[ 16 | 29 ]    Batch:[ 40 | 130 ]    loss_giou: 5.7399    loss_conf: 1.5782    loss_cls: 4.8944    loss: 12.2126    lr: 4.61869e-05\n",
      "Epoch:[ 16 | 29 ]    Batch:[ 50 | 130 ]    loss_giou: 5.7681    loss_conf: 1.6270    loss_cls: 4.9300    loss: 12.3250    lr: 4.57793e-05\n",
      "Epoch:[ 16 | 29 ]    Batch:[ 60 | 130 ]    loss_giou: 5.7581    loss_conf: 1.6759    loss_cls: 5.0703    loss: 12.5043    lr: 4.5372e-05\n",
      "Epoch:[ 16 | 29 ]    Batch:[ 70 | 130 ]    loss_giou: 5.7606    loss_conf: 1.6891    loss_cls: 4.9536    loss: 12.4033    lr: 4.4965e-05\n",
      "Epoch:[ 16 | 29 ]    Batch:[ 80 | 130 ]    loss_giou: 5.7912    loss_conf: 1.7114    loss_cls: 5.1450    loss: 12.6476    lr: 4.45584e-05\n",
      "Epoch:[ 16 | 29 ]    Batch:[ 90 | 130 ]    loss_giou: 5.8075    loss_conf: 1.7073    loss_cls: 5.2281    loss: 12.7429    lr: 4.41523e-05\n",
      "Epoch:[ 16 | 29 ]    Batch:[ 100 | 130 ]    loss_giou: 5.8008    loss_conf: 1.7068    loss_cls: 5.1802    loss: 12.6879    lr: 4.37465e-05\n",
      "Epoch:[ 16 | 29 ]    Batch:[ 110 | 130 ]    loss_giou: 5.7857    loss_conf: 1.7032    loss_cls: 5.0762    loss: 12.5651    lr: 4.33412e-05\n",
      "Epoch:[ 16 | 29 ]    Batch:[ 120 | 130 ]    loss_giou: 5.7709    loss_conf: 1.6886    loss_cls: 5.0882    loss: 12.5477    lr: 4.29365e-05\n",
      "Epoch:[ 16 | 29 ]    Batch:[ 130 | 130 ]    loss_giou: 5.7673    loss_conf: 1.6933    loss_cls: 5.0503    loss: 12.5110    lr: 4.25322e-05\n",
      "save model:  ./weight/best.pt\n",
      "Epoch:[ 17 | 29 ]    Batch:[ 0 | 130 ]    loss_giou: 6.0887    loss_conf: 2.0793    loss_cls: 4.8560    loss: 13.0240    lr: 4.24918e-05\n",
      "Epoch:[ 17 | 29 ]    Batch:[ 10 | 130 ]    loss_giou: 5.6953    loss_conf: 1.6791    loss_cls: 5.2752    loss: 12.6496    lr: 4.20881e-05\n",
      "Epoch:[ 17 | 29 ]    Batch:[ 20 | 130 ]    loss_giou: 5.6058    loss_conf: 1.6117    loss_cls: 5.1717    loss: 12.3891    lr: 4.1685e-05\n",
      "Epoch:[ 17 | 29 ]    Batch:[ 30 | 130 ]    loss_giou: 5.6250    loss_conf: 1.6642    loss_cls: 5.1220    loss: 12.4111    lr: 4.12825e-05\n",
      "Epoch:[ 17 | 29 ]    Batch:[ 40 | 130 ]    loss_giou: 5.6653    loss_conf: 1.6692    loss_cls: 4.9778    loss: 12.3124    lr: 4.08807e-05\n",
      "Epoch:[ 17 | 29 ]    Batch:[ 50 | 130 ]    loss_giou: 5.6765    loss_conf: 1.6779    loss_cls: 4.8803    loss: 12.2347    lr: 4.04795e-05\n",
      "Epoch:[ 17 | 29 ]    Batch:[ 60 | 130 ]    loss_giou: 5.6827    loss_conf: 1.6996    loss_cls: 4.8761    loss: 12.2585    lr: 4.00789e-05\n",
      "Epoch:[ 17 | 29 ]    Batch:[ 70 | 130 ]    loss_giou: 5.6663    loss_conf: 1.6851    loss_cls: 4.9043    loss: 12.2557    lr: 3.96791e-05\n",
      "Epoch:[ 17 | 29 ]    Batch:[ 80 | 130 ]    loss_giou: 5.6541    loss_conf: 1.6661    loss_cls: 4.7784    loss: 12.0985    lr: 3.92801e-05\n",
      "Epoch:[ 17 | 29 ]    Batch:[ 90 | 130 ]    loss_giou: 5.6620    loss_conf: 1.6743    loss_cls: 4.8677    loss: 12.2040    lr: 3.88818e-05\n",
      "Epoch:[ 17 | 29 ]    Batch:[ 100 | 130 ]    loss_giou: 5.6960    loss_conf: 1.6794    loss_cls: 4.9966    loss: 12.3719    lr: 3.84843e-05\n",
      "Epoch:[ 17 | 29 ]    Batch:[ 110 | 130 ]    loss_giou: 5.7011    loss_conf: 1.7066    loss_cls: 5.0165    loss: 12.4242    lr: 3.80876e-05\n",
      "Epoch:[ 17 | 29 ]    Batch:[ 120 | 130 ]    loss_giou: 5.6740    loss_conf: 1.6922    loss_cls: 4.9280    loss: 12.2942    lr: 3.76918e-05\n",
      "Epoch:[ 17 | 29 ]    Batch:[ 130 | 130 ]    loss_giou: 5.6715    loss_conf: 1.6881    loss_cls: 4.8637    loss: 12.2233    lr: 3.72968e-05\n",
      "save model:  ./weight/best.pt\n",
      "Epoch:[ 18 | 29 ]    Batch:[ 0 | 130 ]    loss_giou: 5.2759    loss_conf: 2.0327    loss_cls: 5.9901    loss: 13.2987    lr: 3.72573e-05\n",
      "Epoch:[ 18 | 29 ]    Batch:[ 10 | 130 ]    loss_giou: 5.4773    loss_conf: 1.6375    loss_cls: 5.0691    loss: 12.1839    lr: 3.68634e-05\n",
      "Epoch:[ 18 | 29 ]    Batch:[ 20 | 130 ]    loss_giou: 5.5579    loss_conf: 1.6166    loss_cls: 4.5884    loss: 11.7628    lr: 3.64704e-05\n",
      "Epoch:[ 18 | 29 ]    Batch:[ 30 | 130 ]    loss_giou: 5.5235    loss_conf: 1.6488    loss_cls: 4.7799    loss: 11.9523    lr: 3.60783e-05\n",
      "Epoch:[ 18 | 29 ]    Batch:[ 40 | 130 ]    loss_giou: 5.5389    loss_conf: 1.6185    loss_cls: 4.6813    loss: 11.8387    lr: 3.56872e-05\n",
      "Epoch:[ 18 | 29 ]    Batch:[ 50 | 130 ]    loss_giou: 5.5418    loss_conf: 1.5931    loss_cls: 4.5017    loss: 11.6366    lr: 3.52971e-05\n",
      "Epoch:[ 18 | 29 ]    Batch:[ 60 | 130 ]    loss_giou: 5.5349    loss_conf: 1.5739    loss_cls: 4.6715    loss: 11.7803    lr: 3.49081e-05\n",
      "Epoch:[ 18 | 29 ]    Batch:[ 70 | 130 ]    loss_giou: 5.5544    loss_conf: 1.5656    loss_cls: 4.8830    loss: 12.0030    lr: 3.45201e-05\n",
      "Epoch:[ 18 | 29 ]    Batch:[ 80 | 130 ]    loss_giou: 5.5590    loss_conf: 1.5933    loss_cls: 4.7962    loss: 11.9485    lr: 3.41332e-05\n",
      "Epoch:[ 18 | 29 ]    Batch:[ 90 | 130 ]    loss_giou: 5.5683    loss_conf: 1.6389    loss_cls: 4.9034    loss: 12.1107    lr: 3.37475e-05\n",
      "Epoch:[ 18 | 29 ]    Batch:[ 100 | 130 ]    loss_giou: 5.5344    loss_conf: 1.6338    loss_cls: 4.8737    loss: 12.0419    lr: 3.33629e-05\n",
      "Epoch:[ 18 | 29 ]    Batch:[ 110 | 130 ]    loss_giou: 5.5250    loss_conf: 1.6104    loss_cls: 4.8555    loss: 11.9909    lr: 3.29794e-05\n",
      "Epoch:[ 18 | 29 ]    Batch:[ 120 | 130 ]    loss_giou: 5.5182    loss_conf: 1.5910    loss_cls: 4.8259    loss: 11.9351    lr: 3.25972e-05\n",
      "Epoch:[ 18 | 29 ]    Batch:[ 130 | 130 ]    loss_giou: 5.5166    loss_conf: 1.5906    loss_cls: 4.8079    loss: 11.9151    lr: 3.22162e-05\n",
      "save model:  ./weight/best.pt\n",
      "Epoch:[ 19 | 29 ]    Batch:[ 0 | 130 ]    loss_giou: 5.6704    loss_conf: 1.4692    loss_cls: 6.0159    loss: 13.1555    lr: 3.21782e-05\n",
      "Epoch:[ 19 | 29 ]    Batch:[ 10 | 130 ]    loss_giou: 5.5516    loss_conf: 1.5204    loss_cls: 4.3974    loss: 11.4694    lr: 3.17985e-05\n",
      "Epoch:[ 19 | 29 ]    Batch:[ 20 | 130 ]    loss_giou: 5.4916    loss_conf: 1.6039    loss_cls: 5.2846    loss: 12.3801    lr: 3.14202e-05\n",
      "Epoch:[ 19 | 29 ]    Batch:[ 30 | 130 ]    loss_giou: 5.5405    loss_conf: 1.6720    loss_cls: 5.4925    loss: 12.7050    lr: 3.10431e-05\n",
      "Epoch:[ 19 | 29 ]    Batch:[ 40 | 130 ]    loss_giou: 5.5713    loss_conf: 1.6534    loss_cls: 5.3552    loss: 12.5799    lr: 3.06674e-05\n",
      "Epoch:[ 19 | 29 ]    Batch:[ 50 | 130 ]    loss_giou: 5.5307    loss_conf: 1.6139    loss_cls: 5.2242    loss: 12.3689    lr: 3.0293e-05\n",
      "Epoch:[ 19 | 29 ]    Batch:[ 60 | 130 ]    loss_giou: 5.5163    loss_conf: 1.6103    loss_cls: 4.9839    loss: 12.1106    lr: 2.992e-05\n",
      "Epoch:[ 19 | 29 ]    Batch:[ 70 | 130 ]    loss_giou: 5.5297    loss_conf: 1.6022    loss_cls: 4.9759    loss: 12.1078    lr: 2.95485e-05\n",
      "Epoch:[ 19 | 29 ]    Batch:[ 80 | 130 ]    loss_giou: 5.5240    loss_conf: 1.5832    loss_cls: 5.0164    loss: 12.1237    lr: 2.91783e-05\n",
      "Epoch:[ 19 | 29 ]    Batch:[ 90 | 130 ]    loss_giou: 5.4961    loss_conf: 1.5672    loss_cls: 4.9394    loss: 12.0028    lr: 2.88096e-05\n",
      "Epoch:[ 19 | 29 ]    Batch:[ 100 | 130 ]    loss_giou: 5.4921    loss_conf: 1.5636    loss_cls: 4.9414    loss: 11.9971    lr: 2.84424e-05\n",
      "Epoch:[ 19 | 29 ]    Batch:[ 110 | 130 ]    loss_giou: 5.4977    loss_conf: 1.5690    loss_cls: 4.8232    loss: 11.8899    lr: 2.80767e-05\n",
      "Epoch:[ 19 | 29 ]    Batch:[ 120 | 130 ]    loss_giou: 5.4914    loss_conf: 1.5663    loss_cls: 4.8444    loss: 11.9021    lr: 2.77126e-05\n",
      "Epoch:[ 19 | 29 ]    Batch:[ 130 | 130 ]    loss_giou: 5.4919    loss_conf: 1.5684    loss_cls: 4.8033    loss: 11.8636    lr: 2.735e-05\n",
      "save model:  ./weight/best.pt\n",
      "Epoch:[ 20 | 29 ]    Batch:[ 0 | 130 ]    loss_giou: 5.7229    loss_conf: 1.6279    loss_cls: 8.4356    loss: 15.7864    lr: 2.73138e-05\n",
      "Epoch:[ 20 | 29 ]    Batch:[ 10 | 130 ]    loss_giou: 5.5768    loss_conf: 1.6012    loss_cls: 4.9352    loss: 12.1132    lr: 2.69529e-05\n",
      "Epoch:[ 20 | 29 ]    Batch:[ 20 | 130 ]    loss_giou: 5.4668    loss_conf: 1.5844    loss_cls: 5.5245    loss: 12.5758    lr: 2.65937e-05\n",
      "Epoch:[ 20 | 29 ]    Batch:[ 30 | 130 ]    loss_giou: 5.4119    loss_conf: 1.5818    loss_cls: 5.2702    loss: 12.2639    lr: 2.62361e-05\n",
      "Epoch:[ 20 | 29 ]    Batch:[ 40 | 130 ]    loss_giou: 5.3616    loss_conf: 1.5172    loss_cls: 4.9944    loss: 11.8732    lr: 2.58801e-05\n",
      "Epoch:[ 20 | 29 ]    Batch:[ 50 | 130 ]    loss_giou: 5.3435    loss_conf: 1.5057    loss_cls: 4.8385    loss: 11.6877    lr: 2.55258e-05\n",
      "Epoch:[ 20 | 29 ]    Batch:[ 60 | 130 ]    loss_giou: 5.3207    loss_conf: 1.4912    loss_cls: 4.8273    loss: 11.6393    lr: 2.51733e-05\n",
      "Epoch:[ 20 | 29 ]    Batch:[ 70 | 130 ]    loss_giou: 5.3323    loss_conf: 1.4927    loss_cls: 4.8488    loss: 11.6739    lr: 2.48224e-05\n",
      "Epoch:[ 20 | 29 ]    Batch:[ 80 | 130 ]    loss_giou: 5.3134    loss_conf: 1.4690    loss_cls: 4.7324    loss: 11.5148    lr: 2.44733e-05\n",
      "Epoch:[ 20 | 29 ]    Batch:[ 90 | 130 ]    loss_giou: 5.3281    loss_conf: 1.4774    loss_cls: 4.6937    loss: 11.4992    lr: 2.4126e-05\n",
      "Epoch:[ 20 | 29 ]    Batch:[ 100 | 130 ]    loss_giou: 5.3229    loss_conf: 1.4841    loss_cls: 4.7911    loss: 11.5981    lr: 2.37806e-05\n",
      "Epoch:[ 20 | 29 ]    Batch:[ 110 | 130 ]    loss_giou: 5.3155    loss_conf: 1.4804    loss_cls: 4.7710    loss: 11.5670    lr: 2.34369e-05\n",
      "Epoch:[ 20 | 29 ]    Batch:[ 120 | 130 ]    loss_giou: 5.3140    loss_conf: 1.4648    loss_cls: 4.8231    loss: 11.6019    lr: 2.30951e-05\n",
      "Epoch:[ 20 | 29 ]    Batch:[ 130 | 130 ]    loss_giou: 5.3184    loss_conf: 1.4844    loss_cls: 4.8616    loss: 11.6645    lr: 2.27551e-05\n",
      "save model:  ./weight/best.pt\n",
      "Epoch:[ 21 | 29 ]    Batch:[ 0 | 130 ]    loss_giou: 5.3571    loss_conf: 1.7510    loss_cls: 5.0897    loss: 12.1978    lr: 2.27212e-05\n",
      "Epoch:[ 21 | 29 ]    Batch:[ 10 | 130 ]    loss_giou: 5.4419    loss_conf: 1.5902    loss_cls: 5.0147    loss: 12.0468    lr: 2.23834e-05\n",
      "Epoch:[ 21 | 29 ]    Batch:[ 20 | 130 ]    loss_giou: 5.4211    loss_conf: 1.5441    loss_cls: 5.0840    loss: 12.0491    lr: 2.20475e-05\n",
      "Epoch:[ 21 | 29 ]    Batch:[ 30 | 130 ]    loss_giou: 5.3165    loss_conf: 1.4933    loss_cls: 4.8795    loss: 11.6893    lr: 2.17135e-05\n",
      "Epoch:[ 21 | 29 ]    Batch:[ 40 | 130 ]    loss_giou: 5.2967    loss_conf: 1.5186    loss_cls: 4.9048    loss: 11.7201    lr: 2.13815e-05\n",
      "Epoch:[ 21 | 29 ]    Batch:[ 50 | 130 ]    loss_giou: 5.2882    loss_conf: 1.5050    loss_cls: 4.7578    loss: 11.5511    lr: 2.10514e-05\n",
      "Epoch:[ 21 | 29 ]    Batch:[ 60 | 130 ]    loss_giou: 5.2684    loss_conf: 1.5088    loss_cls: 4.9842    loss: 11.7614    lr: 2.07234e-05\n",
      "Epoch:[ 21 | 29 ]    Batch:[ 70 | 130 ]    loss_giou: 5.2440    loss_conf: 1.5118    loss_cls: 4.8640    loss: 11.6198    lr: 2.03974e-05\n",
      "Epoch:[ 21 | 29 ]    Batch:[ 80 | 130 ]    loss_giou: 5.2361    loss_conf: 1.5155    loss_cls: 4.8209    loss: 11.5724    lr: 2.00735e-05\n",
      "Epoch:[ 21 | 29 ]    Batch:[ 90 | 130 ]    loss_giou: 5.2153    loss_conf: 1.5072    loss_cls: 4.6684    loss: 11.3909    lr: 1.97517e-05\n",
      "Epoch:[ 21 | 29 ]    Batch:[ 100 | 130 ]    loss_giou: 5.2060    loss_conf: 1.4786    loss_cls: 4.5978    loss: 11.2824    lr: 1.9432e-05\n",
      "Epoch:[ 21 | 29 ]    Batch:[ 110 | 130 ]    loss_giou: 5.2100    loss_conf: 1.4788    loss_cls: 4.5535    loss: 11.2423    lr: 1.91143e-05\n",
      "Epoch:[ 21 | 29 ]    Batch:[ 120 | 130 ]    loss_giou: 5.1934    loss_conf: 1.4758    loss_cls: 4.5795    loss: 11.2487    lr: 1.87989e-05\n",
      "Epoch:[ 21 | 29 ]    Batch:[ 130 | 130 ]    loss_giou: 5.2045    loss_conf: 1.4811    loss_cls: 4.5431    loss: 11.2286    lr: 1.84856e-05\n",
      "save model:  ./weight/best.pt\n",
      "Epoch:[ 22 | 29 ]    Batch:[ 0 | 130 ]    loss_giou: 5.0862    loss_conf: 1.6304    loss_cls: 3.1572    loss: 9.8738    lr: 1.84544e-05\n",
      "Epoch:[ 22 | 29 ]    Batch:[ 10 | 130 ]    loss_giou: 5.0849    loss_conf: 1.3640    loss_cls: 4.8736    loss: 11.3225    lr: 1.81435e-05\n",
      "Epoch:[ 22 | 29 ]    Batch:[ 20 | 130 ]    loss_giou: 5.1469    loss_conf: 1.5260    loss_cls: 4.7873    loss: 11.4601    lr: 1.78348e-05\n",
      "Epoch:[ 22 | 29 ]    Batch:[ 30 | 130 ]    loss_giou: 5.1338    loss_conf: 1.5471    loss_cls: 4.5958    loss: 11.2767    lr: 1.75284e-05\n",
      "Epoch:[ 22 | 29 ]    Batch:[ 40 | 130 ]    loss_giou: 5.1700    loss_conf: 1.5273    loss_cls: 4.5844    loss: 11.2818    lr: 1.72242e-05\n",
      "Epoch:[ 22 | 29 ]    Batch:[ 50 | 130 ]    loss_giou: 5.1756    loss_conf: 1.5368    loss_cls: 4.4472    loss: 11.1596    lr: 1.69223e-05\n",
      "Epoch:[ 22 | 29 ]    Batch:[ 60 | 130 ]    loss_giou: 5.1880    loss_conf: 1.5418    loss_cls: 4.4787    loss: 11.2085    lr: 1.66227e-05\n",
      "Epoch:[ 22 | 29 ]    Batch:[ 70 | 130 ]    loss_giou: 5.1577    loss_conf: 1.5192    loss_cls: 4.3796    loss: 11.0565    lr: 1.63254e-05\n",
      "Epoch:[ 22 | 29 ]    Batch:[ 80 | 130 ]    loss_giou: 5.1519    loss_conf: 1.4813    loss_cls: 4.3278    loss: 10.9609    lr: 1.60304e-05\n",
      "Epoch:[ 22 | 29 ]    Batch:[ 90 | 130 ]    loss_giou: 5.1516    loss_conf: 1.4718    loss_cls: 4.2875    loss: 10.9108    lr: 1.57378e-05\n",
      "Epoch:[ 22 | 29 ]    Batch:[ 100 | 130 ]    loss_giou: 5.1488    loss_conf: 1.4653    loss_cls: 4.3697    loss: 10.9838    lr: 1.54476e-05\n",
      "Epoch:[ 22 | 29 ]    Batch:[ 110 | 130 ]    loss_giou: 5.1503    loss_conf: 1.4585    loss_cls: 4.3271    loss: 10.9359    lr: 1.51598e-05\n",
      "Epoch:[ 22 | 29 ]    Batch:[ 120 | 130 ]    loss_giou: 5.1372    loss_conf: 1.4562    loss_cls: 4.2489    loss: 10.8423    lr: 1.48744e-05\n",
      "Epoch:[ 22 | 29 ]    Batch:[ 130 | 130 ]    loss_giou: 5.1316    loss_conf: 1.4432    loss_cls: 4.1978    loss: 10.7726    lr: 1.45914e-05\n",
      "save model:  ./weight/best.pt\n",
      "Epoch:[ 23 | 29 ]    Batch:[ 0 | 130 ]    loss_giou: 5.7243    loss_conf: 1.9574    loss_cls: 5.6910    loss: 13.3727    lr: 1.45632e-05\n",
      "Epoch:[ 23 | 29 ]    Batch:[ 10 | 130 ]    loss_giou: 5.2205    loss_conf: 1.5018    loss_cls: 4.2342    loss: 10.9565    lr: 1.4283e-05\n",
      "Epoch:[ 23 | 29 ]    Batch:[ 20 | 130 ]    loss_giou: 5.0666    loss_conf: 1.3825    loss_cls: 3.7634    loss: 10.2125    lr: 1.40052e-05\n",
      "Epoch:[ 23 | 29 ]    Batch:[ 30 | 130 ]    loss_giou: 5.0656    loss_conf: 1.4019    loss_cls: 3.8889    loss: 10.3564    lr: 1.37299e-05\n",
      "Epoch:[ 23 | 29 ]    Batch:[ 40 | 130 ]    loss_giou: 5.0622    loss_conf: 1.4105    loss_cls: 4.0013    loss: 10.4740    lr: 1.34571e-05\n",
      "Epoch:[ 23 | 29 ]    Batch:[ 50 | 130 ]    loss_giou: 5.0676    loss_conf: 1.4538    loss_cls: 4.0658    loss: 10.5873    lr: 1.31868e-05\n",
      "Epoch:[ 23 | 29 ]    Batch:[ 60 | 130 ]    loss_giou: 5.0239    loss_conf: 1.4634    loss_cls: 4.0508    loss: 10.5381    lr: 1.29191e-05\n",
      "Epoch:[ 23 | 29 ]    Batch:[ 70 | 130 ]    loss_giou: 5.0361    loss_conf: 1.4582    loss_cls: 4.0355    loss: 10.5299    lr: 1.2654e-05\n",
      "Epoch:[ 23 | 29 ]    Batch:[ 80 | 130 ]    loss_giou: 5.0235    loss_conf: 1.4344    loss_cls: 4.1080    loss: 10.5659    lr: 1.23914e-05\n",
      "Epoch:[ 23 | 29 ]    Batch:[ 90 | 130 ]    loss_giou: 5.0342    loss_conf: 1.4479    loss_cls: 4.1136    loss: 10.5957    lr: 1.21315e-05\n",
      "Epoch:[ 23 | 29 ]    Batch:[ 100 | 130 ]    loss_giou: 5.0350    loss_conf: 1.4560    loss_cls: 4.1227    loss: 10.6137    lr: 1.18742e-05\n",
      "Epoch:[ 23 | 29 ]    Batch:[ 110 | 130 ]    loss_giou: 5.0371    loss_conf: 1.4642    loss_cls: 4.0745    loss: 10.5758    lr: 1.16195e-05\n",
      "Epoch:[ 23 | 29 ]    Batch:[ 120 | 130 ]    loss_giou: 5.0325    loss_conf: 1.4596    loss_cls: 4.0889    loss: 10.5810    lr: 1.13675e-05\n",
      "Epoch:[ 23 | 29 ]    Batch:[ 130 | 130 ]    loss_giou: 5.0364    loss_conf: 1.4684    loss_cls: 4.0633    loss: 10.5681    lr: 1.11182e-05\n",
      "save model:  ./weight/best.pt\n",
      "Epoch:[ 24 | 29 ]    Batch:[ 0 | 130 ]    loss_giou: 5.3416    loss_conf: 1.6446    loss_cls: 8.0714    loss: 15.0576    lr: 1.10934e-05\n",
      "Epoch:[ 24 | 29 ]    Batch:[ 10 | 130 ]    loss_giou: 4.9997    loss_conf: 1.3280    loss_cls: 4.9736    loss: 11.3012    lr: 1.0847e-05\n",
      "Epoch:[ 24 | 29 ]    Batch:[ 20 | 130 ]    loss_giou: 4.9068    loss_conf: 1.3462    loss_cls: 4.6999    loss: 10.9530    lr: 1.06034e-05\n",
      "Epoch:[ 24 | 29 ]    Batch:[ 30 | 130 ]    loss_giou: 4.8635    loss_conf: 1.2663    loss_cls: 4.2524    loss: 10.3823    lr: 1.03624e-05\n",
      "Epoch:[ 24 | 29 ]    Batch:[ 40 | 130 ]    loss_giou: 4.8355    loss_conf: 1.2723    loss_cls: 4.0540    loss: 10.1618    lr: 1.01242e-05\n",
      "Epoch:[ 24 | 29 ]    Batch:[ 50 | 130 ]    loss_giou: 4.8690    loss_conf: 1.3180    loss_cls: 4.1118    loss: 10.2988    lr: 9.88881e-06\n",
      "Epoch:[ 24 | 29 ]    Batch:[ 60 | 130 ]    loss_giou: 4.9128    loss_conf: 1.3631    loss_cls: 4.1771    loss: 10.4531    lr: 9.65616e-06\n",
      "Epoch:[ 24 | 29 ]    Batch:[ 70 | 130 ]    loss_giou: 4.9314    loss_conf: 1.3903    loss_cls: 4.2092    loss: 10.5310    lr: 9.42631e-06\n",
      "Epoch:[ 24 | 29 ]    Batch:[ 80 | 130 ]    loss_giou: 4.9314    loss_conf: 1.3848    loss_cls: 4.1402    loss: 10.4564    lr: 9.19926e-06\n",
      "Epoch:[ 24 | 29 ]    Batch:[ 90 | 130 ]    loss_giou: 4.9208    loss_conf: 1.3870    loss_cls: 4.1319    loss: 10.4397    lr: 8.97503e-06\n",
      "Epoch:[ 24 | 29 ]    Batch:[ 100 | 130 ]    loss_giou: 4.9294    loss_conf: 1.3960    loss_cls: 4.0910    loss: 10.4164    lr: 8.75365e-06\n",
      "Epoch:[ 24 | 29 ]    Batch:[ 110 | 130 ]    loss_giou: 4.9384    loss_conf: 1.4019    loss_cls: 4.1005    loss: 10.4408    lr: 8.53512e-06\n",
      "Epoch:[ 24 | 29 ]    Batch:[ 120 | 130 ]    loss_giou: 4.9346    loss_conf: 1.3859    loss_cls: 4.0593    loss: 10.3797    lr: 8.31946e-06\n",
      "Epoch:[ 24 | 29 ]    Batch:[ 130 | 130 ]    loss_giou: 4.9474    loss_conf: 1.3879    loss_cls: 4.0379    loss: 10.3733    lr: 8.10669e-06\n",
      "save model:  ./weight/best.pt\n",
      "Epoch:[ 25 | 29 ]    Batch:[ 0 | 130 ]    loss_giou: 5.0380    loss_conf: 1.2270    loss_cls: 6.0678    loss: 12.3328    lr: 8.08557e-06\n",
      "Epoch:[ 25 | 29 ]    Batch:[ 10 | 130 ]    loss_giou: 4.8511    loss_conf: 1.2937    loss_cls: 4.0326    loss: 10.1774    lr: 7.87598e-06\n",
      "Epoch:[ 25 | 29 ]    Batch:[ 20 | 130 ]    loss_giou: 4.8397    loss_conf: 1.2849    loss_cls: 3.8636    loss: 9.9882    lr: 7.66931e-06\n",
      "Epoch:[ 25 | 29 ]    Batch:[ 30 | 130 ]    loss_giou: 4.8662    loss_conf: 1.4081    loss_cls: 3.8677    loss: 10.1420    lr: 7.46557e-06\n",
      "Epoch:[ 25 | 29 ]    Batch:[ 40 | 130 ]    loss_giou: 4.9029    loss_conf: 1.4391    loss_cls: 3.8388    loss: 10.1809    lr: 7.26478e-06\n",
      "Epoch:[ 25 | 29 ]    Batch:[ 50 | 130 ]    loss_giou: 4.9577    loss_conf: 1.4504    loss_cls: 4.1702    loss: 10.5783    lr: 7.06693e-06\n",
      "Epoch:[ 25 | 29 ]    Batch:[ 60 | 130 ]    loss_giou: 4.9238    loss_conf: 1.4047    loss_cls: 4.2709    loss: 10.5994    lr: 6.87206e-06\n",
      "Epoch:[ 25 | 29 ]    Batch:[ 70 | 130 ]    loss_giou: 4.9186    loss_conf: 1.4058    loss_cls: 4.2344    loss: 10.5588    lr: 6.68017e-06\n",
      "Epoch:[ 25 | 29 ]    Batch:[ 80 | 130 ]    loss_giou: 4.9179    loss_conf: 1.3928    loss_cls: 4.3073    loss: 10.6180    lr: 6.49128e-06\n",
      "Epoch:[ 25 | 29 ]    Batch:[ 90 | 130 ]    loss_giou: 4.9112    loss_conf: 1.3920    loss_cls: 4.3319    loss: 10.6350    lr: 6.3054e-06\n",
      "Epoch:[ 25 | 29 ]    Batch:[ 100 | 130 ]    loss_giou: 4.9317    loss_conf: 1.4027    loss_cls: 4.3458    loss: 10.6801    lr: 6.12254e-06\n",
      "Epoch:[ 25 | 29 ]    Batch:[ 110 | 130 ]    loss_giou: 4.9314    loss_conf: 1.4198    loss_cls: 4.3358    loss: 10.6870    lr: 5.94272e-06\n",
      "Epoch:[ 25 | 29 ]    Batch:[ 120 | 130 ]    loss_giou: 4.9392    loss_conf: 1.4239    loss_cls: 4.4136    loss: 10.7767    lr: 5.76594e-06\n",
      "Epoch:[ 25 | 29 ]    Batch:[ 130 | 130 ]    loss_giou: 4.9248    loss_conf: 1.4066    loss_cls: 4.4001    loss: 10.7315    lr: 5.59222e-06\n",
      "save model:  ./weight/best.pt\n",
      "Epoch:[ 26 | 29 ]    Batch:[ 0 | 130 ]    loss_giou: 5.4812    loss_conf: 1.3094    loss_cls: 4.6204    loss: 11.4109    lr: 5.57502e-06\n",
      "Epoch:[ 26 | 29 ]    Batch:[ 10 | 130 ]    loss_giou: 5.0351    loss_conf: 1.3980    loss_cls: 3.9135    loss: 10.3466    lr: 5.40468e-06\n",
      "Epoch:[ 26 | 29 ]    Batch:[ 20 | 130 ]    loss_giou: 5.0265    loss_conf: 1.4676    loss_cls: 4.2875    loss: 10.7816    lr: 5.23742e-06\n",
      "Epoch:[ 26 | 29 ]    Batch:[ 30 | 130 ]    loss_giou: 4.9445    loss_conf: 1.4035    loss_cls: 4.0530    loss: 10.4010    lr: 5.07326e-06\n",
      "Epoch:[ 26 | 29 ]    Batch:[ 40 | 130 ]    loss_giou: 4.9773    loss_conf: 1.4293    loss_cls: 3.9340    loss: 10.3407    lr: 4.91221e-06\n",
      "Epoch:[ 26 | 29 ]    Batch:[ 50 | 130 ]    loss_giou: 4.9437    loss_conf: 1.3712    loss_cls: 3.8890    loss: 10.2039    lr: 4.75427e-06\n",
      "Epoch:[ 26 | 29 ]    Batch:[ 60 | 130 ]    loss_giou: 4.9163    loss_conf: 1.3394    loss_cls: 3.8473    loss: 10.1029    lr: 4.59946e-06\n",
      "Epoch:[ 26 | 29 ]    Batch:[ 70 | 130 ]    loss_giou: 4.9130    loss_conf: 1.3549    loss_cls: 3.8022    loss: 10.0701    lr: 4.44779e-06\n",
      "Epoch:[ 26 | 29 ]    Batch:[ 80 | 130 ]    loss_giou: 4.9086    loss_conf: 1.3390    loss_cls: 3.7957    loss: 10.0432    lr: 4.29927e-06\n",
      "Epoch:[ 26 | 29 ]    Batch:[ 90 | 130 ]    loss_giou: 4.8780    loss_conf: 1.3265    loss_cls: 3.7908    loss: 9.9953    lr: 4.15391e-06\n",
      "Epoch:[ 26 | 29 ]    Batch:[ 100 | 130 ]    loss_giou: 4.8576    loss_conf: 1.3341    loss_cls: 3.8275    loss: 10.0191    lr: 4.01172e-06\n",
      "Epoch:[ 26 | 29 ]    Batch:[ 110 | 130 ]    loss_giou: 4.8550    loss_conf: 1.3327    loss_cls: 3.8297    loss: 10.0175    lr: 3.8727e-06\n",
      "Epoch:[ 26 | 29 ]    Batch:[ 120 | 130 ]    loss_giou: 4.8490    loss_conf: 1.3268    loss_cls: 3.8659    loss: 10.0417    lr: 3.73688e-06\n",
      "Epoch:[ 26 | 29 ]    Batch:[ 130 | 130 ]    loss_giou: 4.8429    loss_conf: 1.3228    loss_cls: 3.9083    loss: 10.0740    lr: 3.60425e-06\n",
      "save model:  ./weight/best.pt\n",
      "Epoch:[ 27 | 29 ]    Batch:[ 0 | 130 ]    loss_giou: 5.4117    loss_conf: 1.9126    loss_cls: 4.3225    loss: 11.6468    lr: 3.59117e-06\n",
      "Epoch:[ 27 | 29 ]    Batch:[ 10 | 130 ]    loss_giou: 4.9255    loss_conf: 1.3615    loss_cls: 3.8936    loss: 10.1806    lr: 3.46207e-06\n",
      "Epoch:[ 27 | 29 ]    Batch:[ 20 | 130 ]    loss_giou: 4.8912    loss_conf: 1.4319    loss_cls: 4.3777    loss: 10.7008    lr: 3.33619e-06\n",
      "Epoch:[ 27 | 29 ]    Batch:[ 30 | 130 ]    loss_giou: 4.8898    loss_conf: 1.4647    loss_cls: 4.3643    loss: 10.7187    lr: 3.21353e-06\n",
      "Epoch:[ 27 | 29 ]    Batch:[ 40 | 130 ]    loss_giou: 4.8745    loss_conf: 1.4502    loss_cls: 4.2877    loss: 10.6123    lr: 3.09411e-06\n",
      "Epoch:[ 27 | 29 ]    Batch:[ 50 | 130 ]    loss_giou: 4.9099    loss_conf: 1.4541    loss_cls: 4.4959    loss: 10.8599    lr: 2.97793e-06\n",
      "Epoch:[ 27 | 29 ]    Batch:[ 60 | 130 ]    loss_giou: 4.9272    loss_conf: 1.4604    loss_cls: 4.5119    loss: 10.8996    lr: 2.865e-06\n",
      "Epoch:[ 27 | 29 ]    Batch:[ 70 | 130 ]    loss_giou: 4.9014    loss_conf: 1.4557    loss_cls: 4.5873    loss: 10.9445    lr: 2.75533e-06\n",
      "Epoch:[ 27 | 29 ]    Batch:[ 80 | 130 ]    loss_giou: 4.8809    loss_conf: 1.4408    loss_cls: 4.4657    loss: 10.7875    lr: 2.64892e-06\n",
      "Epoch:[ 27 | 29 ]    Batch:[ 90 | 130 ]    loss_giou: 4.8781    loss_conf: 1.4215    loss_cls: 4.3446    loss: 10.6442    lr: 2.54578e-06\n",
      "Epoch:[ 27 | 29 ]    Batch:[ 100 | 130 ]    loss_giou: 4.8828    loss_conf: 1.4065    loss_cls: 4.4441    loss: 10.7334    lr: 2.44593e-06\n",
      "Epoch:[ 27 | 29 ]    Batch:[ 110 | 130 ]    loss_giou: 4.8791    loss_conf: 1.3919    loss_cls: 4.3915    loss: 10.6625    lr: 2.34935e-06\n",
      "Epoch:[ 27 | 29 ]    Batch:[ 120 | 130 ]    loss_giou: 4.8747    loss_conf: 1.4011    loss_cls: 4.3727    loss: 10.6486    lr: 2.25608e-06\n",
      "Epoch:[ 27 | 29 ]    Batch:[ 130 | 130 ]    loss_giou: 4.8645    loss_conf: 1.3893    loss_cls: 4.4061    loss: 10.6599    lr: 2.1661e-06\n",
      "save model:  ./weight/best.pt\n",
      "Epoch:[ 28 | 29 ]    Batch:[ 0 | 130 ]    loss_giou: 5.0398    loss_conf: 1.7236    loss_cls: 5.8348    loss: 12.5981    lr: 2.15728e-06\n",
      "Epoch:[ 28 | 29 ]    Batch:[ 10 | 130 ]    loss_giou: 4.9200    loss_conf: 1.5995    loss_cls: 4.2419    loss: 10.7614    lr: 2.07094e-06\n",
      "Epoch:[ 28 | 29 ]    Batch:[ 20 | 130 ]    loss_giou: 4.8638    loss_conf: 1.4659    loss_cls: 3.9108    loss: 10.2405    lr: 1.98791e-06\n",
      "Epoch:[ 28 | 29 ]    Batch:[ 30 | 130 ]    loss_giou: 4.8076    loss_conf: 1.3842    loss_cls: 3.9123    loss: 10.1041    lr: 1.9082e-06\n",
      "Epoch:[ 28 | 29 ]    Batch:[ 40 | 130 ]    loss_giou: 4.8010    loss_conf: 1.3677    loss_cls: 3.9203    loss: 10.0891    lr: 1.83181e-06\n",
      "Epoch:[ 28 | 29 ]    Batch:[ 50 | 130 ]    loss_giou: 4.7823    loss_conf: 1.3372    loss_cls: 3.9115    loss: 10.0310    lr: 1.75874e-06\n",
      "Epoch:[ 28 | 29 ]    Batch:[ 60 | 130 ]    loss_giou: 4.7949    loss_conf: 1.3924    loss_cls: 3.8270    loss: 10.0143    lr: 1.68902e-06\n",
      "Epoch:[ 28 | 29 ]    Batch:[ 70 | 130 ]    loss_giou: 4.8231    loss_conf: 1.3821    loss_cls: 3.9772    loss: 10.1824    lr: 1.62262e-06\n",
      "Epoch:[ 28 | 29 ]    Batch:[ 80 | 130 ]    loss_giou: 4.8129    loss_conf: 1.3875    loss_cls: 3.9352    loss: 10.1357    lr: 1.55958e-06\n",
      "Epoch:[ 28 | 29 ]    Batch:[ 90 | 130 ]    loss_giou: 4.8038    loss_conf: 1.3760    loss_cls: 3.9326    loss: 10.1124    lr: 1.49987e-06\n",
      "Epoch:[ 28 | 29 ]    Batch:[ 100 | 130 ]    loss_giou: 4.7967    loss_conf: 1.3689    loss_cls: 3.9425    loss: 10.1082    lr: 1.44352e-06\n",
      "Epoch:[ 28 | 29 ]    Batch:[ 110 | 130 ]    loss_giou: 4.7895    loss_conf: 1.3552    loss_cls: 3.9730    loss: 10.1176    lr: 1.39053e-06\n",
      "Epoch:[ 28 | 29 ]    Batch:[ 120 | 130 ]    loss_giou: 4.8032    loss_conf: 1.3728    loss_cls: 3.9920    loss: 10.1680    lr: 1.34089e-06\n",
      "Epoch:[ 28 | 29 ]    Batch:[ 130 | 130 ]    loss_giou: 4.7898    loss_conf: 1.3681    loss_cls: 3.9150    loss: 10.0729    lr: 1.29461e-06\n",
      "save model:  ./weight/best.pt\n",
      "Epoch:[ 29 | 29 ]    Batch:[ 0 | 130 ]    loss_giou: 4.7210    loss_conf: 0.9029    loss_cls: 5.2318    loss: 10.8557    lr: 1.29017e-06\n",
      "Epoch:[ 29 | 29 ]    Batch:[ 10 | 130 ]    loss_giou: 4.8163    loss_conf: 1.2121    loss_cls: 3.8291    loss: 9.8576    lr: 1.2476e-06\n",
      "Epoch:[ 29 | 29 ]    Batch:[ 20 | 130 ]    loss_giou: 4.6998    loss_conf: 1.2119    loss_cls: 3.6820    loss: 9.5936    lr: 1.20839e-06\n",
      "Epoch:[ 29 | 29 ]    Batch:[ 30 | 130 ]    loss_giou: 4.7205    loss_conf: 1.2271    loss_cls: 3.5768    loss: 9.5245    lr: 1.17255e-06\n",
      "Epoch:[ 29 | 29 ]    Batch:[ 40 | 130 ]    loss_giou: 4.7210    loss_conf: 1.2453    loss_cls: 3.5508    loss: 9.5171    lr: 1.14009e-06\n",
      "Epoch:[ 29 | 29 ]    Batch:[ 50 | 130 ]    loss_giou: 4.7647    loss_conf: 1.2710    loss_cls: 4.0352    loss: 10.0709    lr: 1.11101e-06\n",
      "Epoch:[ 29 | 29 ]    Batch:[ 60 | 130 ]    loss_giou: 4.7430    loss_conf: 1.2589    loss_cls: 4.0225    loss: 10.0244    lr: 1.0853e-06\n",
      "Epoch:[ 29 | 29 ]    Batch:[ 70 | 130 ]    loss_giou: 4.7403    loss_conf: 1.2585    loss_cls: 3.8827    loss: 9.8816    lr: 1.06297e-06\n",
      "Epoch:[ 29 | 29 ]    Batch:[ 80 | 130 ]    loss_giou: 4.7388    loss_conf: 1.2744    loss_cls: 3.7379    loss: 9.7511    lr: 1.04402e-06\n",
      "Epoch:[ 29 | 29 ]    Batch:[ 90 | 130 ]    loss_giou: 4.7431    loss_conf: 1.2650    loss_cls: 3.7022    loss: 9.7103    lr: 1.02845e-06\n",
      "Epoch:[ 29 | 29 ]    Batch:[ 100 | 130 ]    loss_giou: 4.7655    loss_conf: 1.3236    loss_cls: 3.7181    loss: 9.8072    lr: 1.01626e-06\n",
      "Epoch:[ 29 | 29 ]    Batch:[ 110 | 130 ]    loss_giou: 4.7800    loss_conf: 1.3205    loss_cls: 3.7778    loss: 9.8783    lr: 1.00746e-06\n",
      "Epoch:[ 29 | 29 ]    Batch:[ 120 | 130 ]    loss_giou: 4.7847    loss_conf: 1.3235    loss_cls: 3.7688    loss: 9.8770    lr: 1.00205e-06\n",
      "Epoch:[ 29 | 29 ]    Batch:[ 130 | 130 ]    loss_giou: 4.7860    loss_conf: 1.3113    loss_cls: 3.7947    loss: 9.8921    lr: 1.00002e-06\n",
      "save model:  ./weight/best.pt\n"
     ]
    }
   ],
   "source": [
    "Trainer().train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]='0'\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "import utils.gpu as gpu\n",
    "from model.yolov3 import Yolov3\n",
    "from tqdm import tqdm\n",
    "from utils.tools import *\n",
    "from eval.evaluator import Evaluator\n",
    "import argparse\n",
    "import config.yolov3_config_voc as cfg\n",
    "from utils.visualize import *\n",
    "\n",
    "\n",
    "class Tester(object):\n",
    "    def __init__(self,\n",
    "                 weight_path='./weight/best.pt',\n",
    "                 gpu_id=0,\n",
    "                 img_size=416,\n",
    "                 visiual='./data/test/',\n",
    "                 eval=False\n",
    "                 ):\n",
    "        self.img_size = img_size\n",
    "        self.__num_class = cfg.DATA[\"NUM\"]\n",
    "        self.__conf_threshold = cfg.TEST[\"CONF_THRESH\"]\n",
    "        self.__nms_threshold = cfg.TEST[\"NMS_THRESH\"]\n",
    "        self.__device = gpu.select_device(gpu_id)\n",
    "        self.__multi_scale_test = cfg.TEST[\"MULTI_SCALE_TEST\"]\n",
    "        self.__flip_test = cfg.TEST[\"FLIP_TEST\"]\n",
    "\n",
    "        self.__visiual = visiual\n",
    "        self.__eval = eval\n",
    "        self.__classes = cfg.DATA[\"CLASSES\"]\n",
    "\n",
    "        self.__model = Yolov3().to(self.__device)\n",
    "\n",
    "        # self.__load_model_weights(weight_path)\n",
    "        self.__load_model_weights(weight_path)\n",
    "\n",
    "#         self.__evalter = Evaluator(self.__model, visiual=True)\n",
    "        self.__evalter = Evaluator(self.__model)\n",
    "\n",
    "\n",
    "    def __load_model_weights(self, weight_path):\n",
    "        print(\"loading weight file from : {}\".format(weight_path))\n",
    "\n",
    "        weight = os.path.join(weight_path)\n",
    "        chkpt = torch.load(weight, map_location=self.__device)\n",
    "        self.__model.load_state_dict(chkpt['model'])\n",
    "#         self.__model.load_state_dict(chkpt)\n",
    "        print(\"loading weight file is done\")\n",
    "        del chkpt\n",
    "\n",
    "\n",
    "    def test(self):\n",
    "        if self.__visiual:\n",
    "            imgs = os.listdir(self.__visiual)\n",
    "            for v in imgs:\n",
    "                path = os.path.join(self.__visiual, v)\n",
    "#                 print(\"test images : {}\".format(path))\n",
    "                img = cv2.imread(path)\n",
    "                assert img is not None\n",
    "                bboxes_prd = self.__evalter.get_bbox(img)\n",
    "                if bboxes_prd.shape[0] != 0:\n",
    "                    boxes = bboxes_prd[..., :4]\n",
    "                    class_inds = bboxes_prd[..., 5].astype(np.int32)\n",
    "                    scores = bboxes_prd[..., 4]\n",
    "\n",
    "                    visualize_boxes(image=img, boxes=boxes, labels=class_inds, probs=scores, class_labels=self.__classes)\n",
    "                    path = os.path.join(cfg.PROJECT_PATH, \"data/pred/{}\".format(v))\n",
    "\n",
    "                    cv2.imwrite(path, img)\n",
    "                    print(\"saved images : {}\".format(path))\n",
    "\n",
    "\n",
    "        if self.__eval:\n",
    "            mAP = 0\n",
    "            print('*' * 20 + \"Validate\" + '*' * 20)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                APs = Evaluator(self.__model).APs_voc(self.__multi_scale_test, self.__flip_test)\n",
    "\n",
    "                for i in APs:\n",
    "                    print(\"{} --> mAP : {}\".format(i, APs[i]))\n",
    "                    mAP += APs[i]\n",
    "                mAP = mAP / self.__num_class\n",
    "                print('mAP:%g' % (mAP))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CUDA device0 _CudaDeviceProperties(name='TITAN RTX', total_memory=24220MB)\n",
      "initing Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "initing BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "initing Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "initing BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "initing Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "initing BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "initing Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "initing BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "initing Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "initing BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "initing Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "initing BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "initing Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "initing BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "initing Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "initing BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "initing Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "initing BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "initing Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "initing BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "initing Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "initing BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "initing Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "initing BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "initing Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "initing BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "initing Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "initing BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "initing Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "initing BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "initing Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "initing BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "initing Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "initing BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "initing Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "initing BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "initing Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "initing BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "initing Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "initing BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "initing Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "initing BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "initing Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "initing BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "initing Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "initing BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "initing Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "initing BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "initing Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "initing BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "initing Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "initing BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "initing Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "initing BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "initing Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "initing BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "initing Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "initing BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "initing Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "initing BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "initing Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "initing BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "initing Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "initing BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "initing Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "initing BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "initing Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "initing BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "initing Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "initing BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "initing Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "initing BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "initing Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "initing BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "initing Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "initing BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "initing Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "initing BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "initing Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "initing BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "initing Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "initing BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "initing Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "initing BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "initing Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "initing BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "initing Conv2d(512, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "initing BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "initing Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "initing BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "initing Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "initing BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "initing Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "initing BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "initing Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "initing BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "initing Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "initing BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "initing Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "initing BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "initing Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "initing BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "initing Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "initing BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "initing Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "initing BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "initing Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "initing BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "initing Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "initing BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "initing Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "initing BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "initing Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "initing BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "initing Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "initing BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "initing Conv2d(1024, 33, kernel_size=(1, 1), stride=(1, 1))\n",
      "initing Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "initing BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "initing Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "initing BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "initing Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "initing BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "initing Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "initing BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "initing Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "initing BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "initing Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "initing BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "initing Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "initing BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "initing Conv2d(512, 33, kernel_size=(1, 1), stride=(1, 1))\n",
      "initing Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "initing BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "initing Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "initing BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "initing Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "initing BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "initing Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "initing BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "initing Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "initing BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "initing Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "initing BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "initing Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "initing BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "initing Conv2d(256, 33, kernel_size=(1, 1), stride=(1, 1))\n",
      "loading weight file from : ./weight/best.pt\n",
      "loading weight file is done\n",
      "saved images : ./data/pred/5d3fa62be4b0aecb2989e41e.jpg\n",
      "saved images : ./data/pred/5d688b4de4b0aa5058add4fe.jpg\n",
      "saved images : ./data/pred/5d4ee394e4b0aecb2992bcb8.jpg\n",
      "saved images : ./data/pred/5d20c0eee4b05338ae270310.jpg\n",
      "saved images : ./data/pred/5d581da7e4b0aecb2996cf3d.jpg\n",
      "saved images : ./data/pred/5d19b699e4b0b6098b829847.jpg\n",
      "saved images : ./data/pred/5d0ca14ce4b0b6098b7b0b44.jpg\n",
      "saved images : ./data/pred/5d1ae7a5e4b05338ae22b3ae.jpg\n",
      "saved images : ./data/pred/5d4bb80ae4b0aa50589f1546.jpg\n",
      "saved images : ./data/pred/5d39587de4b0aa505893fb89.jpg\n",
      "saved images : ./data/pred/5d6610b1e4b0aa5058ac464e.jpg\n",
      "saved images : ./data/pred/5d1ea796e4b05338ae25435c.jpg\n",
      "saved images : ./data/pred/5d26df0ce4b0aa50588719e0.jpg\n",
      "saved images : ./data/pred/5d4934f2e4b0aecb298f8256.jpg\n",
      "saved images : ./data/pred/5d40e476e4b0aa505898a2ad.jpg\n",
      "saved images : ./data/pred/5d5b5cb5e4b0aecb29980fe2.jpg\n",
      "saved images : ./data/pred/5d097f71e4b0b6098b782aa5.jpg\n",
      "saved images : ./data/pred/5d097f4de4b0b6098b782aa0.jpg\n",
      "saved images : ./data/pred/5d5f77dae4b0aa5058a94910.jpg\n",
      "saved images : ./data/pred/5d40fb30e4b0aecb298b24eb.jpg\n",
      "saved images : ./data/pred/5d16abcce4b0b6098b81301f.jpg\n",
      "saved images : ./data/pred/5d3c6bb0e4b0aa5058959a7c.jpg\n",
      "saved images : ./data/pred/5d48d91ce4b0aecb298eda61.jpg\n",
      "saved images : ./data/pred/5d5f9e81e4b0aa5058a97656.jpg\n",
      "saved images : ./data/pred/5d2542ace4b0b6098b8ba8fe.jpg\n",
      "saved images : ./data/pred/5d4386a8e4b0aecb298c6aed.jpg\n",
      "saved images : ./data/pred/5d3165bae4b0aecb2981c1e3.jpg\n",
      "saved images : ./data/pred/5d5a3242e4b0aa5058a5eedd.jpg\n",
      "saved images : ./data/pred/5d648e7ce4b0aecb299c9f0e.jpg\n",
      "saved images : ./data/pred/5d2ea830e4b0aecb297fa9dc.jpg\n",
      "saved images : ./data/pred/5d1da8aae4b0b6098b8662c9.jpg\n",
      "saved images : ./data/pred/5d15625fe4b0b6098b807bdb.jpg\n",
      "saved images : ./data/pred/5d0ca002e4b0b6098b7b0758.jpg\n",
      "saved images : ./data/pred/5d560ca7e4b0aecb2995d0ca.jpg\n",
      "saved images : ./data/pred/5d1ef4f5e4b0b6098b873747.jpg\n",
      "saved images : ./data/pred/5d0af02fe4b0b6098b791403.jpg\n",
      "saved images : ./data/pred/5d0e499de4b05338ae1aa978.jpg\n",
      "saved images : ./data/pred/5d4248fee4b0aecb298bbf9e.jpg\n",
      "saved images : ./data/pred/5d31639fe4b0aa50588e8685.jpg\n",
      "saved images : ./data/pred/5d282843e4b0aecb297bde7c.jpg\n",
      "saved images : ./data/pred/5d4bbb10e4b0aa50589f1c7f.jpg\n",
      "saved images : ./data/pred/5d2c1d29e4b0aa505889ca8b.jpg\n",
      "saved images : ./data/pred/5d5363a4e4b0aecb299461ab.jpg\n",
      "saved images : ./data/pred/5d1014c9e4b05338ae1ae024.jpg\n",
      "saved images : ./data/pred/5d14619ce4b05338ae1edb87.jpg\n",
      "saved images : ./data/pred/5d22b37be4b05338ae27d4b5.jpg\n",
      "saved images : ./data/pred/5d2bcfc8e4b0aecb297ccb90.jpg\n",
      "saved images : ./data/pred/5d37a9f9e4b0aa5058928d56.jpg\n",
      "saved images : ./data/pred/5d0c9fade4b0b6098b7b0673.jpg\n",
      "saved images : ./data/pred/5d48ee1ce4b0aa50589ced43.jpg\n",
      "saved images : ./data/pred/5d19bb86e4b0b6098b82a09f.jpg\n",
      "saved images : ./data/pred/5d1b0b27e4b05338ae22e0eb.jpg\n",
      "saved images : ./data/pred/5d47d255e4b0aecb298e5ddf.jpg\n",
      "saved images : ./data/pred/5d3e984fe4b0aecb29895a7c.jpg\n",
      "saved images : ./data/pred/5d47a1a1e4b0aa50589be1a4.jpg\n",
      "saved images : ./data/pred/5d254ad7e4b05338ae2a24f1.jpg\n",
      "saved images : ./data/pred/5d16aad7e4b0b6098b812ea0.jpg\n",
      "saved images : ./data/pred/5d300b3be4b0aa50588d698e.jpg\n",
      "saved images : ./data/pred/5d2541aee4b05338ae2a1605.jpg\n",
      "saved images : ./data/pred/5d5e4747e4b0aecb299a0923.jpg\n",
      "saved images : ./data/pred/5d48dd9fe4b0aecb298ee8c9.jpg\n",
      "saved images : ./data/pred/5d1aa301e4b05338ae224e92.jpg\n",
      "saved images : ./data/pred/5d12ba3ce4b05338ae1d1839.jpg\n",
      "saved images : ./data/pred/5d2e63f3e4b0aa50588bb3a8.jpg\n",
      "saved images : ./data/pred/5d12b9ebe4b0b6098b7e21f9.jpg\n",
      "saved images : ./data/pred/5d1ee20fe4b05338ae25c10a.jpg\n",
      "saved images : ./data/pred/5d3f8edae4b0aecb2989c627.jpg\n",
      "saved images : ./data/pred/5d0c7239e4b05338ae19ce91.jpg\n",
      "saved images : ./data/pred/5d445d91e4b0aecb298d65f0.jpg\n",
      "saved images : ./data/pred/5d12bab8e4b05338ae1d18b7.jpg\n",
      "saved images : ./data/pred/5d12ba0de4b0b6098b7e2220.jpg\n",
      "saved images : ./data/pred/5d2d368de4b0aa50588aa22d.jpg\n",
      "saved images : ./data/pred/5d16aba8e4b0b6098b812fcf.jpg\n",
      "saved images : ./data/pred/5d4cd0d7e4b0aa50589f8f1c.jpg\n",
      "saved images : ./data/pred/5d521e6ce4b0aecb2993a1a0.jpg\n",
      "saved images : ./data/pred/5d142ea1e4b05338ae1e7f5f.jpg\n",
      "saved images : ./data/pred/5d0c8640e4b05338ae19fb02.jpg\n",
      "saved images : ./data/pred/5d099a43e4b05338ae17768d.jpg\n",
      "saved images : ./data/pred/5d50c687e4b0aecb2992fb4a.jpg\n",
      "saved images : ./data/pred/5d479cbce4b0aa50589bdaba.jpg\n",
      "saved images : ./data/pred/5d520186e4b0aecb299389e2.jpg\n",
      "saved images : ./data/pred/5d41276fe4b0aa50589917ea.jpg\n",
      "saved images : ./data/pred/5d0ca06ee4b0b6098b7b090a.jpg\n",
      "saved images : ./data/pred/5d581ce4e4b0aecb2996cef1.jpg\n",
      "saved images : ./data/pred/5d102ae8e4b0b6098b7bdd37.jpg\n",
      "saved images : ./data/pred/5d5b4038e4b0aa5058a67133.jpg\n",
      "saved images : ./data/pred/5d354ed7e4b0aa505890772e.jpg\n",
      "saved images : ./data/pred/5d0ca1dfe4b05338ae1a2873.jpg\n",
      "saved images : ./data/pred/5d20bbfae4b0b6098b885e63.jpg\n",
      "saved images : ./data/pred/5d5b625ae4b0aa5058a69904.jpg\n",
      "saved images : ./data/pred/5d3a97d4e4b0aa505894db52.jpg\n",
      "saved images : ./data/pred/5d4a3a44e4b0aa50589de2a6.jpg\n",
      "saved images : ./data/pred/5d3e3ecce4b0aecb298863ea.jpg\n",
      "saved images : ./data/pred/5d20b81be4b05338ae26fd08.jpg\n",
      "saved images : ./data/pred/5d2c1940e4b0aa505889c175.jpg\n",
      "saved images : ./data/pred/5d1ad04fe4b05338ae2286c5.jpg\n",
      "saved images : ./data/pred/5d10702be4b05338ae1b7626.jpg\n",
      "saved images : ./data/pred/5d39547be4b0aa505893f73a.jpg\n",
      "saved images : ./data/pred/5d0ca188e4b05338ae1a2802.jpg\n",
      "saved images : ./data/pred/5d2415f2e4b0b6098b8a8db9.jpg\n",
      "saved images : ./data/pred/5d4bd905e4b0aa50589f4e64.jpg\n",
      "saved images : ./data/pred/5d268ca9e4b0aa505886807b.jpg\n",
      "saved images : ./data/pred/5d365d3ce4b0aa5058912f34.jpg\n",
      "saved images : ./data/pred/5d19a09be4b05338ae213750.jpg\n",
      "saved images : ./data/pred/5d4ee446e4b0aa5058a0e9f0.jpg\n",
      "saved images : ./data/pred/5d0b2405e4b05338ae18a316.jpg\n",
      "saved images : ./data/pred/5d5e2291e4b0aa5058a85939.jpg\n",
      "saved images : ./data/pred/5d68be28e4b0aecb299f65ff.jpg\n",
      "saved images : ./data/pred/5d2d27c9e4b0aecb297e1e9a.jpg\n",
      "saved images : ./data/pred/5d565421e4b0aecb29963d20.jpg\n",
      "saved images : ./data/pred/5d1083e7e4b05338ae1b8de0.jpg\n",
      "saved images : ./data/pred/5d107627e4b0b6098b7c6d37.jpg\n",
      "saved images : ./data/pred/5d4ee2f8e4b0aecb2992bbf1.jpg\n",
      "saved images : ./data/pred/5d0b2f43e4b05338ae18af44.jpg\n",
      "saved images : ./data/pred/5d48e292e4b0aecb298ef3b7.jpg\n",
      "saved images : ./data/pred/5d3e8716e4b0aa505896d629.jpg\n",
      "saved images : ./data/pred/5d4d0aace4b0aecb2991ca69.jpg\n",
      "saved images : ./data/pred/5d3557fde4b0aa50589084a0.jpg\n",
      "saved images : ./data/pred/5d097f47e4b05338ae1764e2.jpg\n",
      "saved images : ./data/pred/5d65ed1fe4b0aecb299d6470.jpg\n",
      "saved images : ./data/pred/5d50dadbe4b0aa5058a14904.jpg\n",
      "saved images : ./data/pred/5d396209e4b0aa5058940d68.jpg\n",
      "saved images : ./data/pred/5d676af1e4b0aecb299e8259.jpg\n",
      "saved images : ./data/pred/5d5dedcee4b0aecb299973ad.jpg\n",
      "saved images : ./data/pred/5d65d31ee4b0aecb299d44ac.jpg\n",
      "saved images : ./data/pred/5d0c685ce4b0b6098b7aa1de.jpg\n",
      "saved images : ./data/pred/5d65f0ace4b0aecb299d6986.jpg\n",
      "saved images : ./data/pred/5d47baf6e4b0aecb298e4181.jpg\n",
      "saved images : ./data/pred/5d1aa2d5e4b05338ae224e5e.jpg\n",
      "saved images : ./data/pred/5d146152e4b0b6098b7ffaa1.jpg\n",
      "saved images : ./data/pred/5d1426f1e4b05338ae1e78bc.jpg\n",
      "saved images : ./data/pred/5d22b27ae4b0b6098b89383d.jpg\n",
      "saved images : ./data/pred/5d45a5cae4b0aa50589b7c64.jpg\n",
      "saved images : ./data/pred/5d3e503ce4b0aa50589623ec.jpg\n",
      "saved images : ./data/pred/5d36b693e4b0aecb2984d6ca.jpg\n",
      "saved images : ./data/pred/5d537322e4b0aecb299479dc.jpg\n",
      "saved images : ./data/pred/5d6ddd05e4b0aecb29a17f6d.jpg\n",
      "saved images : ./data/pred/5d22ecc1e4b05338ae284580.jpg\n",
      "saved images : ./data/pred/5d48c7e4e4b0aa50589c961a.jpg\n",
      "saved images : ./data/pred/5d6f0637e4b0aa5058b15f95.jpg\n",
      "saved images : ./data/pred/5d101498e4b0b6098b7bc69d.jpg\n",
      "saved images : ./data/pred/5d5ca9d0e4b0aecb2998f0ce.jpg\n",
      "saved images : ./data/pred/5d354ab0e4b0aa5058906ca0.jpg\n",
      "saved images : ./data/pred/5d131b0be4b05338ae1dc3e1.jpg\n",
      "saved images : ./data/pred/5d10428be4b05338ae1b233b.jpg\n",
      "saved images : ./data/pred/5d19b029e4b0b6098b828cf8.jpg\n",
      "saved images : ./data/pred/5d5f894fe4b0aecb299abc46.jpg\n",
      "saved images : ./data/pred/5d5cdb9de4b0aecb29992a5c.jpg\n",
      "saved images : ./data/pred/5d26e289e4b0aecb297b13d4.jpg\n",
      "saved images : ./data/pred/5d0b2c8ae4b0b6098b798add.jpg\n",
      "saved images : ./data/pred/5d45a53be4b0aa50589b7c35.jpg\n",
      "saved images : ./data/pred/5d101e9fe4b0b6098b7bcf25.jpg\n",
      "saved images : ./data/pred/5d31506ae4b0aecb2981a7c3.jpg\n",
      "saved images : ./data/pred/5d3a51d9e4b0aa50589466e0.jpg\n",
      "saved images : ./data/pred/5d65ea76e4b0aecb299d6080.jpg\n",
      "saved images : ./data/pred/5d50f2e4e4b0aa5058a16681.jpg\n",
      "saved images : ./data/pred/5d53adc2e4b0aecb2994d329.jpg\n",
      "saved images : ./data/pred/5d22eb0ee4b05338ae2842bd.jpg\n",
      "saved images : ./data/pred/5d097fa0e4b0b6098b782aa9.jpg\n",
      "saved images : ./data/pred/5d663b24e4b0aecb299dd4ef.jpg\n",
      "saved images : ./data/pred/5d3c6f57e4b0aa5058959c85.jpg\n",
      "saved images : ./data/pred/5d314cc0e4b0aecb2981a222.jpg\n",
      "saved images : ./data/pred/5d3e4579e4b0aecb29886f7b.jpg\n",
      "saved images : ./data/pred/5d4edc9be4b0aa5058a0e431.jpg\n",
      "saved images : ./data/pred/5d15628fe4b05338ae1f57d7.jpg\n",
      "saved images : ./data/pred/5d22eb74e4b05338ae284366.jpg\n",
      "saved images : ./data/pred/5d45a920e4b0aa50589b7e47.jpg\n",
      "saved images : ./data/pred/5d676040e4b0aecb299e71d0.jpg\n",
      "saved images : ./data/pred/5d098290e4b0b6098b782bbe.jpg\n",
      "saved images : ./data/pred/5d1bf8c0e4b05338ae23506a.jpg\n",
      "saved images : ./data/pred/5d445fa3e4b0aa50589b29cb.jpg\n",
      "saved images : ./data/pred/5d537ea3e4b0aa5058a2e05e.jpg\n",
      "saved images : ./data/pred/5d282397e4b0aecb297bd598.jpg\n",
      "saved images : ./data/pred/5d102e33e4b05338ae1afa23.jpg\n",
      "saved images : ./data/pred/5d197128e4b0b6098b8205e4.jpg\n",
      "saved images : ./data/pred/5d3e9d33e4b0aecb298964e2.jpg\n",
      "saved images : ./data/pred/5d5e278fe4b0aa5058a86179.jpg\n",
      "saved images : ./data/pred/5d37eae7e4b0aecb2985b613.jpg\n",
      "saved images : ./data/pred/5d09d9e8e4b05338ae17d480.jpg\n",
      "saved images : ./data/pred/5d14603de4b05338ae1ed6a6.jpg\n",
      "saved images : ./data/pred/5d0979bde4b05338ae1762cb.jpg\n",
      "saved images : ./data/pred/5d16abeee4b0b6098b813053.jpg\n",
      "saved images : ./data/pred/5d64975fe4b0aa5058ab4cf0.jpg\n",
      "saved images : ./data/pred/5d1aa2aee4b05338ae224e3a.jpg\n",
      "saved images : ./data/pred/5d3c6c01e4b0aa5058959a8b.jpg\n",
      "saved images : ./data/pred/5d29495ce4b0aecb297c85f8.jpg\n",
      "saved images : ./data/pred/5d6a8ca0e4b0aecb299ff8f1.jpg\n",
      "saved images : ./data/pred/5d355329e4b0aecb29837166.jpg\n",
      "saved images : ./data/pred/5d1c1d72e4b0b6098b84e775.jpg\n",
      "saved images : ./data/pred/5d0ca215e4b0b6098b7b0c03.jpg\n",
      "saved images : ./data/pred/5d5c912ae4b0aecb2998d3e8.jpg\n",
      "saved images : ./data/pred/5d5e221de4b0aecb2999c575.jpg\n",
      "saved images : ./data/pred/5d689526e4b0aecb299f2846.jpg\n",
      "saved images : ./data/pred/5d4ee55ce4b0aecb2992bd85.jpg\n",
      "saved images : ./data/pred/5d2d2463e4b0aa50588a88a6.jpg\n",
      "saved images : ./data/pred/5d36755ae4b0aecb29843cbb.jpg\n",
      "saved images : ./data/pred/5d0c8b13e4b05338ae19ff8b.jpg\n",
      "saved images : ./data/pred/5d2fff0fe4b0aecb2980bcfb.jpg\n",
      "saved images : ./data/pred/5d5cad40e4b0aecb2998f7c2.jpg\n",
      "saved images : ./data/pred/5d107309e4b0b6098b7c6918.jpg\n",
      "saved images : ./data/pred/5d156229e4b0b6098b807bbf.jpg\n",
      "saved images : ./data/pred/5d40ddf8e4b0aecb298aee33.jpg\n",
      "saved images : ./data/pred/5d12e17ae4b0b6098b7e60d5.jpg\n",
      "saved images : ./data/pred/5d2548afe4b05338ae2a221a.jpg\n",
      "saved images : ./data/pred/5d099c91e4b0b6098b784073.jpg\n",
      "saved images : ./data/pred/5d5a5279e4b0aecb2997acb6.jpg\n",
      "saved images : ./data/pred/5d2557fce4b05338ae2a36f5.jpg\n",
      "saved images : ./data/pred/5d5ca620e4b0aecb2998e83e.jpg\n",
      "saved images : ./data/pred/5d5e43ffe4b0aa5058a895f0.jpg\n",
      "saved images : ./data/pred/5d394f9ee4b0aecb2986ab09.jpg\n",
      "saved images : ./data/pred/5d0ad37be4b0b6098b78f38b.jpg\n",
      "saved images : ./data/pred/5d3fe20ee4b0aecb298a4a47.jpg\n",
      "saved images : ./data/pred/5d53769be4b0aa5058a2d64b.jpg\n",
      "saved images : ./data/pred/5d16ab79e4b0b6098b812f8e.jpg\n",
      "saved images : ./data/pred/5d3fdfdde4b0aa505897f7d7.jpg\n",
      "saved images : ./data/pred/5d67671be4b0aecb299e7b4f.jpg\n",
      "saved images : ./data/pred/5d565e09e4b0aa5058a4ad82.jpg\n",
      "saved images : ./data/pred/5d116ac9e4b0b6098b7ccaaa.jpg\n",
      "saved images : ./data/pred/5d29491fe4b0aa505888bf34.jpg\n",
      "saved images : ./data/pred/5d65cfdde4b0aecb299d436e.jpg\n",
      "saved images : ./data/pred/5d3ea716e4b0aa50589719c1.jpg\n",
      "saved images : ./data/pred/5d0c9fd8e4b0b6098b7b06d7.jpg\n",
      "saved images : ./data/pred/5d0ad684e4b05338ae182301.jpg\n",
      "saved images : ./data/pred/5d5f43ffe4b0aecb299a8b36.jpg\n",
      "saved images : ./data/pred/5d268293e4b0aa5058867176.jpg\n",
      "saved images : ./data/pred/5d316844e4b0aa50588e8b41.jpg\n",
      "saved images : ./data/pred/5d0ca036e4b05338ae1a25a4.jpg\n",
      "saved images : ./data/pred/5d630257e4b0aa5058aa04f2.jpg\n",
      "saved images : ./data/pred/5d12c403e4b05338ae1d24ab.jpg\n",
      "saved images : ./data/pred/5d355c2ee4b0aecb29837b1e.jpg\n",
      "Done test\n"
     ]
    }
   ],
   "source": [
    "Tester().test()\n",
    "\n",
    "print(\"Done test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:detect]",
   "language": "python",
   "name": "conda-env-detect-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

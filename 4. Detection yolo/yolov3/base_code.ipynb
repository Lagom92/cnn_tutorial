{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Base code\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device:  cuda\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "import logging\n",
    "import utils.gpu as gpu\n",
    "from model.yolov3 import Yolov3\n",
    "from model.loss.yolo_loss import YoloV3Loss\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "from torch.utils.data import DataLoader\n",
    "import utils.datasets as data\n",
    "import time\n",
    "import random\n",
    "import argparse\n",
    "from eval.evaluator import *\n",
    "from utils.tools import *\n",
    "from tensorboardX import SummaryWriter\n",
    "import config.yolov3_config_voc as cfg\n",
    "from utils import cosine_lr_scheduler\n",
    "\n",
    "\n",
    "# GPU device\n",
    "# Check GPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"Device: \", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer(object):\n",
    "    def __init__(self,  weight_path='./weight/darknet53_448.weights', resume=None, gpu_id='0'):\n",
    "#         init_seeds(0)\n",
    "        self.device = gpu.select_device(gpu_id)\n",
    "        self.start_epoch = 0\n",
    "        self.best_mAP = 0.\n",
    "        self.epochs = cfg.TRAIN[\"EPOCHS\"]\n",
    "        self.weight_path = weight_path\n",
    "        self.multi_scale_train = cfg.TRAIN[\"MULTI_SCALE_TRAIN\"]\n",
    "        self.train_dataset = data.VocDataset(anno_file_type=\"train\", img_size=cfg.TRAIN[\"TRAIN_IMG_SIZE\"])\n",
    "        self.train_dataloader = DataLoader(self.train_dataset,\n",
    "                                           batch_size=cfg.TRAIN[\"BATCH_SIZE\"],\n",
    "                                           num_workers=cfg.TRAIN[\"NUMBER_WORKERS\"],\n",
    "                                           shuffle=True)\n",
    "        self.yolov3 = Yolov3().to(self.device)\n",
    "        # self.yolov3.apply(tools.weights_init_normal)\n",
    "\n",
    "        self.optimizer = optim.SGD(self.yolov3.parameters(), lr=cfg.TRAIN[\"LR_INIT\"],\n",
    "                                   momentum=cfg.TRAIN[\"MOMENTUM\"], weight_decay=cfg.TRAIN[\"WEIGHT_DECAY\"])\n",
    "        #self.optimizer = optim.Adam(self.yolov3.parameters(), lr = lr_init, weight_decay=0.9995)\n",
    "\n",
    "        self.criterion = YoloV3Loss(anchors=cfg.MODEL[\"ANCHORS\"], strides=cfg.MODEL[\"STRIDES\"],\n",
    "                                    iou_threshold_loss=cfg.TRAIN[\"IOU_THRESHOLD_LOSS\"])\n",
    "\n",
    "        self.scheduler = cosine_lr_scheduler.CosineDecayLR(self.optimizer,\n",
    "                                                          T_max=self.epochs*len(self.train_dataloader),\n",
    "                                                          lr_init=cfg.TRAIN[\"LR_INIT\"],\n",
    "                                                          lr_min=cfg.TRAIN[\"LR_END\"],\n",
    "                                                          warmup=cfg.TRAIN[\"WARMUP_EPOCHS\"]*len(self.train_dataloader))\n",
    "\n",
    "    def train(self):\n",
    "        print(self.yolov3)\n",
    "        print(\"Train datasets number is : {}\".format(len(self.train_dataset)))\n",
    "        best_loss = 100.0\n",
    "\n",
    "        for epoch in range(self.start_epoch, self.epochs):\n",
    "            self.yolov3.train()\n",
    "\n",
    "            mloss = torch.zeros(4)\n",
    "            for i, (imgs, label_sbbox, label_mbbox, label_lbbox, sbboxes, mbboxes, lbboxes)  in enumerate(self.train_dataloader):\n",
    "\n",
    "                self.scheduler.step(len(self.train_dataloader)*epoch + i)\n",
    "\n",
    "                imgs = imgs.to(self.device)\n",
    "                label_sbbox = label_sbbox.to(self.device)\n",
    "                label_mbbox = label_mbbox.to(self.device)\n",
    "                label_lbbox = label_lbbox.to(self.device)\n",
    "                sbboxes = sbboxes.to(self.device)\n",
    "                mbboxes = mbboxes.to(self.device)\n",
    "                lbboxes = lbboxes.to(self.device)\n",
    "\n",
    "                p, p_d = self.yolov3(imgs)\n",
    "\n",
    "                loss, loss_giou, loss_conf, loss_cls = self.criterion(p, p_d, label_sbbox, label_mbbox,\n",
    "                                                  label_lbbox, sbboxes, mbboxes, lbboxes)\n",
    "\n",
    "                self.optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "\n",
    "                # Update running mean of tracked metrics\n",
    "                loss_items = torch.tensor([loss_giou, loss_conf, loss_cls, loss])\n",
    "                mloss = (mloss * i + loss_items) / (i + 1)\n",
    "\n",
    "                # Print batch results\n",
    "                if i%10==0:\n",
    "                    s = ('Epoch:[ %d | %d ]    Batch:[ %d | %d ]    loss_giou: %.4f    loss_conf: %.4f    loss_cls: %.4f    loss: %.4f    '\n",
    "                         'lr: %g') % (epoch, self.epochs - 1, i, len(self.train_dataloader) - 1, mloss[0],mloss[1], mloss[2], mloss[3],\n",
    "                                      self.optimizer.param_groups[0]['lr'])\n",
    "                    print(s)\n",
    "                    \n",
    "            # save model\n",
    "            if best_loss > mloss[-1]:\n",
    "                best_loss = mloss[-1]\n",
    "                best_weight = os.path.join(os.path.split(self.weight_path)[0], \"best.pt\")\n",
    "                chkpt = {'epoch': epoch,\n",
    "                        'model': self.yolov3.state_dict(),\n",
    "                        'optimizer': self.optimizer.state_dict()}\n",
    "                print(\"save model: \", best_weight)\n",
    "                \n",
    "                torch.save(chkpt, best_weight)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Trainer().train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]='0'\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "import utils.gpu as gpu\n",
    "from model.yolov3 import Yolov3\n",
    "from tqdm import tqdm\n",
    "from utils.tools import *\n",
    "from eval.evaluator import Evaluator\n",
    "import argparse\n",
    "import config.yolov3_config_voc as cfg\n",
    "from utils.visualize import *\n",
    "\n",
    "\n",
    "class Tester(object):\n",
    "    def __init__(self,\n",
    "                 weight_path='./weight/best.pt',\n",
    "                 gpu_id=0,\n",
    "                 img_size=416,\n",
    "                 visiual='./data/test/',\n",
    "                 eval=False\n",
    "                 ):\n",
    "        self.img_size = img_size\n",
    "        self.__num_class = cfg.DATA[\"NUM\"]\n",
    "        self.__conf_threshold = cfg.TEST[\"CONF_THRESH\"]\n",
    "        self.__nms_threshold = cfg.TEST[\"NMS_THRESH\"]\n",
    "        self.__device = gpu.select_device(gpu_id)\n",
    "        self.__multi_scale_test = cfg.TEST[\"MULTI_SCALE_TEST\"]\n",
    "        self.__flip_test = cfg.TEST[\"FLIP_TEST\"]\n",
    "\n",
    "        self.__visiual = visiual\n",
    "        self.__eval = eval\n",
    "        self.__classes = cfg.DATA[\"CLASSES\"]\n",
    "\n",
    "        self.__model = Yolov3().to(self.__device)\n",
    "\n",
    "        # self.__load_model_weights(weight_path)\n",
    "        self.__load_model_weights(weight_path)\n",
    "\n",
    "#         self.__evalter = Evaluator(self.__model, visiual=True)\n",
    "        self.__evalter = Evaluator(self.__model)\n",
    "\n",
    "\n",
    "    def __load_model_weights(self, weight_path):\n",
    "        print(\"loading weight file from : {}\".format(weight_path))\n",
    "\n",
    "        weight = os.path.join(weight_path)\n",
    "        chkpt = torch.load(weight, map_location=self.__device)\n",
    "        self.__model.load_state_dict(chkpt['model'])\n",
    "#         self.__model.load_state_dict(chkpt)\n",
    "        print(\"loading weight file is done\")\n",
    "        del chkpt\n",
    "\n",
    "\n",
    "    def test(self):\n",
    "        if self.__visiual:\n",
    "            imgs = os.listdir(self.__visiual)\n",
    "            for v in imgs:\n",
    "                path = os.path.join(self.__visiual, v)\n",
    "#                 print(\"test images : {}\".format(path))\n",
    "                img = cv2.imread(path)\n",
    "                assert img is not None\n",
    "                bboxes_prd = self.__evalter.get_bbox(img)\n",
    "                if bboxes_prd.shape[0] != 0:\n",
    "                    boxes = bboxes_prd[..., :4]\n",
    "                    class_inds = bboxes_prd[..., 5].astype(np.int32)\n",
    "                    scores = bboxes_prd[..., 4]\n",
    "\n",
    "                    visualize_boxes(image=img, boxes=boxes, labels=class_inds, probs=scores, class_labels=self.__classes)\n",
    "                    path = os.path.join(cfg.PROJECT_PATH, \"data/pred/{}\".format(v))\n",
    "\n",
    "                    cv2.imwrite(path, img)\n",
    "#                     print(\"saved images : {}\".format(path))\n",
    "\n",
    "\n",
    "        if self.__eval:\n",
    "            mAP = 0\n",
    "            print('*' * 20 + \"Validate\" + '*' * 20)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                APs = Evaluator(self.__model).APs_voc(self.__multi_scale_test, self.__flip_test)\n",
    "\n",
    "                for i in APs:\n",
    "                    print(\"{} --> mAP : {}\".format(i, APs[i]))\n",
    "                    mAP += APs[i]\n",
    "                mAP = mAP / self.__num_class\n",
    "                print('mAP:%g' % (mAP))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tester().test()\n",
    "\n",
    "print(\"Done test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:detect]",
   "language": "python",
   "name": "conda-env-detect-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

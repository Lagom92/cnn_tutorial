{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "supposed-kidney",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "amber-cooking",
   "metadata": {},
   "source": [
    "# data split\n",
    "\n",
    "원본 이미지를 train / test로 나누기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "rational-myanmar",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "inside-agriculture",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44\n",
      "44\n"
     ]
    }
   ],
   "source": [
    "abnormal_lst = os.listdir('../data/abnormal')\n",
    "\n",
    "print(len(abnormal_lst))\n",
    "abnormal = []\n",
    "for ab in abnormal_lst:\n",
    "    abnormal.append(ab.split('.')[0])\n",
    "    \n",
    "    \n",
    "print(len(abnormal))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "sixth-gathering",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'58581e6ee4b005193719746c'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abnormal[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "excellent-witness",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4644"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_lst = os.listdir('../src')\n",
    "\n",
    "len(data_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "educated-disco",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2278 2278\n"
     ]
    }
   ],
   "source": [
    "txt_lst, jpg_lst = [], []\n",
    "for data in data_lst:\n",
    "    if data.split('.')[0] not in abnormal:\n",
    "        if data.endswith('.txt'):\n",
    "            txt_lst.append(data)\n",
    "        else:\n",
    "            jpg_lst.append(data)\n",
    "    \n",
    "txt_lst.sort()\n",
    "jpg_lst.sort()\n",
    "\n",
    "print(len(txt_lst), len(jpg_lst))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "saved-party",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2050, 227)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 9:1 비율(count 계산)\n",
    "int(len(txt_lst)*0.9), int(len(txt_lst)*0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bacterial-mitchell",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['abnormal']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if not(os.path.isdir('../data/')):\n",
    "        os.makedirs(os.path.join('../data/'))\n",
    "\n",
    "os.listdir('../data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "loose-entrepreneur",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2050\n",
      "4100\n"
     ]
    }
   ],
   "source": [
    "path = '../data/org_train/'\n",
    "n = int(len(txt_lst)*0.9)\n",
    "if not(os.path.isdir(path)):\n",
    "        os.makedirs(os.path.join(path))\n",
    "\n",
    "# Train data\n",
    "for data in txt_lst[:n]:\n",
    "    org_data = '../src/' + data\n",
    "    cop_data = path + data\n",
    "    \n",
    "    shutil.copyfile(org_data, cop_data)\n",
    "\n",
    "print(len(os.listdir(path)))\n",
    "\n",
    "for data in jpg_lst[:n]:\n",
    "    org_data = '../src/' + data\n",
    "    cop_data = path + data\n",
    "    \n",
    "    shutil.copyfile(org_data, cop_data)\n",
    "\n",
    "print(len(os.listdir(path)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "curious-presence",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "228\n",
      "456\n"
     ]
    }
   ],
   "source": [
    "path = '../data/org_test/'\n",
    "n = int(len(txt_lst)*0.9)\n",
    "if not(os.path.isdir(path)):\n",
    "        os.makedirs(os.path.join(path))\n",
    "\n",
    "# Test data\n",
    "for data in txt_lst[n:]:\n",
    "    org_data = '../src/' + data\n",
    "    cop_data = path + data\n",
    "    \n",
    "    shutil.copyfile(org_data, cop_data)\n",
    "\n",
    "print(len(os.listdir(path)))\n",
    "\n",
    "for data in jpg_lst[n:]:\n",
    "    org_data = '../src/' + data\n",
    "    cop_data = path + data\n",
    "    \n",
    "    shutil.copyfile(org_data, cop_data)\n",
    "\n",
    "print(len(os.listdir(path)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "functioning-messenger",
   "metadata": {},
   "source": [
    "# Preprocessing\n",
    "\n",
    "이미지 전처리 및 annotation 파일 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "distant-dodge",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import transforms\n",
    "import albumentations.pytorch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import albumentations as A\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"]=10, 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "manufactured-howard",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bounding box 좌표 변경하기\n",
    "def cvt_coordinate(center_x, center_y, w, h):\n",
    "    '''\n",
    "    start_x, start_y: 시작 꼭짓점 좌표 (x, y)\n",
    "    end_x, end_y: 종료 꼭짓점 좌표 (x, y)\n",
    "    '''\n",
    "    start_x, end_x = center_x - (w/2), center_x + (w/2)\n",
    "    start_y, end_y = center_y - (h/2), center_y + (h/2)\n",
    "\n",
    "    return int(start_x), int(start_y), int(end_x), int(end_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "moral-parking",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "empty-wyoming",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4100\n",
      "2050 2050\n"
     ]
    }
   ],
   "source": [
    "# data path 설정\n",
    "DATA_PATH = '../data/org_train/'\n",
    "data_list = os.listdir(DATA_PATH)\n",
    "\n",
    "print(len(data_list))\n",
    "\n",
    "# 이미지와 라벨 데이터 \n",
    "img_list = []\n",
    "txt_list = []\n",
    "\n",
    "for data in data_list:\n",
    "    data = DATA_PATH + data\n",
    "    if data.endswith('txt'):\n",
    "        txt_list.append(data)\n",
    "    else:\n",
    "        img_list.append(data)\n",
    "\n",
    "txt_list.sort()\n",
    "img_list.sort()\n",
    "\n",
    "print(len(img_list), len(txt_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "quiet-destination",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = len(img_list)\n",
    "target_size = 416\n",
    "\n",
    "f = open('../data/train_annotation.txt', 'w')\n",
    "for i in range(n):\n",
    "#     print(img_list[i])\n",
    "#     print(txt_list[i])\n",
    "    \n",
    "    image = cv2.imread(img_list[i])    \n",
    "    df = pd.read_csv(txt_list[i])\n",
    "    \n",
    "    title = img_list[i].split('/')[-1]\n",
    "    \n",
    "    bboxes = []\n",
    "    for i in range(6):\n",
    "        label = str(df.iloc[i][0])\n",
    "        sr = df.iloc[i][1:5].tolist()\n",
    "        x1, y1, x2, y2 = cvt_coordinate(sr[0], sr[1], sr[2], sr[3])\n",
    "        bboxes.append([x1, y1, x2, y2, label])\n",
    "#     print('bboxes: ', bboxes)\n",
    "    \n",
    "    # Transform\n",
    "    transform = A.Compose([\n",
    "        A.LongestMaxSize(max_size=target_size, always_apply=True),\n",
    "        A.PadIfNeeded(target_size, target_size, always_apply=True, border_mode=0, value=[0, 0, 0]),\n",
    "        A.pytorch.transforms.ToTensor()\n",
    "        ],\n",
    "        bbox_params = A.BboxParams(format='pascal_voc')\n",
    "    )\n",
    "    data = transform(image=image, bboxes=bboxes)\n",
    "        \n",
    "    # show image with bbox and labels\n",
    "    img = data['image']\n",
    "    bboxes = data['bboxes']\n",
    "    img = np.array(img.permute(1,2,0))\n",
    "    img = (img*255).astype(np.uint8)\n",
    "    \n",
    "    cv2.imwrite('../data/train/' + title, img)\n",
    "\n",
    "    # bounding box\n",
    "    text = []\n",
    "    for i in range(6):\n",
    "        coor = bboxes[i]\n",
    "        coor = list(map(int, coor))\n",
    "#         img = cv2.rectangle(img, (coor[0], coor[1]), (coor[2], coor[3]), (0, 0, 255), 1)\n",
    "#         cv2.putText(img, str(coor[4]), (coor[0], coor[1]), cv2.FONT_ITALIC, 0.5, (255, 0, 0), 1, cv2.LINE_AA)\n",
    "        \n",
    "        coor = list(map(str, coor))\n",
    "        text.extend(coor)\n",
    "\n",
    "    res = './data/train/'+ title + ' ' + ','.join(text) + '\\n'\n",
    "    f.write(res)\n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "confirmed-cylinder",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "prescription-single",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "456\n",
      "228 228\n"
     ]
    }
   ],
   "source": [
    "# data path 설정\n",
    "DATA_PATH = '../data/org_test/'\n",
    "data_list = os.listdir(DATA_PATH)\n",
    "\n",
    "print(len(data_list))\n",
    "\n",
    "# 이미지와 라벨 데이터 \n",
    "img_list = []\n",
    "txt_list = []\n",
    "\n",
    "for data in data_list:\n",
    "    data = DATA_PATH + data\n",
    "    if data.endswith('txt'):\n",
    "        txt_list.append(data)\n",
    "    else:\n",
    "        img_list.append(data)\n",
    "\n",
    "txt_list.sort()\n",
    "img_list.sort()\n",
    "\n",
    "print(len(img_list), len(txt_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "educational-chinese",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = len(img_list)\n",
    "target_size = 416\n",
    "\n",
    "f = open('../data/test_annotation.txt', 'w')\n",
    "for i in range(n):\n",
    "#     print(img_list[i])\n",
    "#     print(txt_list[i])\n",
    "    \n",
    "    image = cv2.imread(img_list[i])    \n",
    "    df = pd.read_csv(txt_list[i])\n",
    "    \n",
    "    title = img_list[i].split('/')[-1]\n",
    "    \n",
    "    bboxes = []\n",
    "    for i in range(6):\n",
    "        label = str(df.iloc[i][0])\n",
    "        sr = df.iloc[i][1:5].tolist()\n",
    "        x1, y1, x2, y2 = cvt_coordinate(sr[0], sr[1], sr[2], sr[3])\n",
    "        bboxes.append([x1, y1, x2, y2, label])\n",
    "#     print('bboxes: ', bboxes)\n",
    "    \n",
    "    # Transform\n",
    "    transform = A.Compose([\n",
    "        A.LongestMaxSize(max_size=target_size, always_apply=True),\n",
    "        A.PadIfNeeded(target_size, target_size, always_apply=True, border_mode=0, value=[0, 0, 0]),\n",
    "        A.pytorch.transforms.ToTensor()\n",
    "        ],\n",
    "        bbox_params = A.BboxParams(format='pascal_voc')\n",
    "    )\n",
    "    data = transform(image=image, bboxes=bboxes)\n",
    "        \n",
    "    # show image with bbox and labels\n",
    "    img = data['image']\n",
    "    bboxes = data['bboxes']\n",
    "    img = np.array(img.permute(1,2,0))\n",
    "    img = (img*255).astype(np.uint8)\n",
    "    \n",
    "    cv2.imwrite('../data/test/' + title, img)\n",
    "\n",
    "    # bounding box\n",
    "    text = []\n",
    "    for i in range(6):\n",
    "        coor = bboxes[i]\n",
    "        coor = list(map(int, coor))\n",
    "#         img = cv2.rectangle(img, (coor[0], coor[1]), (coor[2], coor[3]), (0, 0, 255), 1)\n",
    "#         cv2.putText(img, str(coor[4]), (coor[0], coor[1]), cv2.FONT_ITALIC, 0.5, (255, 0, 0), 1, cv2.LINE_AA)\n",
    "        \n",
    "        coor = list(map(str, coor))\n",
    "        text.extend(coor)\n",
    "\n",
    "    res = './data/test/'+ title + ' ' + ','.join(text) + '\\n'\n",
    "    f.write(res)\n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "behavioral-elephant",
   "metadata": {},
   "source": [
    "# Edit annotations txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "breeding-rabbit",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_f = open('../data/train_annotation__.txt', mode='w')\n",
    "\n",
    "with open('../data/train_annotation.txt', mode='r') as f:\n",
    "    data = f.readlines()\n",
    "    \n",
    "    for i in range(len(data)):\n",
    "        data_lst = data[i].split(',')\n",
    "        title = data_lst[0]\n",
    "#         title_ = title.replace('data__', 'data')        \n",
    "        val = title.split(' ')\n",
    "        data_lst = val + data_lst[1:]\n",
    "        res = ''\n",
    "        for j in range(len(data_lst)):\n",
    "            res += data_lst[j]\n",
    "            if j % 5 == 0:\n",
    "                res += ' '\n",
    "            else:\n",
    "                res += ','\n",
    "                    \n",
    "        new_f.write(res[:-1])\n",
    "    \n",
    "new_f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "negative-request",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_f = open('../data/test_annotation__.txt', mode='w')\n",
    "\n",
    "with open('../data/test_annotation.txt', mode='r') as f:\n",
    "    data = f.readlines()\n",
    "    \n",
    "    for i in range(len(data)):\n",
    "        data_lst = data[i].split(',')\n",
    "        title = data_lst[0]\n",
    "#         title_ = title.replace('data__', 'data')        \n",
    "        val = title.split(' ')\n",
    "        data_lst = val + data_lst[1:]\n",
    "        res = ''\n",
    "        for j in range(len(data_lst)):\n",
    "            res += data_lst[j]\n",
    "            if j % 5 == 0:\n",
    "                res += ' '\n",
    "            else:\n",
    "                res += ','\n",
    "                    \n",
    "        new_f.write(res[:-1])\n",
    "    \n",
    "new_f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hybrid-growing",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
